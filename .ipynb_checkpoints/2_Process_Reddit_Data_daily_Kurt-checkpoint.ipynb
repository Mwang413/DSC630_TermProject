{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import platform\n",
    "\n",
    "import stoneburner\n",
    "#//*** Custom Functions:\n",
    "#//*** mr_clean_text(input_series)\n",
    "#//*** tokenize_series(input_series)\n",
    "#//*** remove_stop_words(input_series)\n",
    "\n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#//*** Use the whole window in the IPYNB editor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "subreddits = [\"wallstreetbets\", \"stocks\", \"wallstreetbetsOGs\", \"spacs\", \"investing\", \"pennystocks\", \"stockmarket\", \"options\", \"robinhoodpennystocks\", \"wallstreetbetsnew\", \"smallstreetbets\"]\n",
    "filepath = \"./data/\"\n",
    "filename_suffix = \"_comments.csv.zip\"\n",
    "#//*** Maximize columns and rows displayed by pandas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amc']\n",
      "Reading Compressed CSV: ./data/wallstreetbets_comments.csv.zip\n",
      "Reading Compressed CSV: ./data/stocks_comments.csv.zip\n",
      "Reading Compressed CSV: ./data/wallstreetbetsOGs_comments.csv.zip\n",
      "Reading Compressed CSV: ./data/spacs_comments.csv.zip\n",
      "Reading Compressed CSV: ./data/investing_comments.csv.zip\n",
      "Reading Compressed CSV: ./data/pennystocks_comments.csv.zip\n",
      "Reading Compressed CSV: ./data/stockmarket_comments.csv.zip\n",
      "Reading Compressed CSV: ./data/options_comments.csv.zip\n",
      "Reading Compressed CSV: ./data/robinhoodpennystocks_comments.csv.zip\n",
      "Reading Compressed CSV: ./data/wallstreetbetsnew_comments.csv.zip\n",
      "Reading Compressed CSV: ./data/smallstreetbets_comments.csv.zip\n",
      "Files Loaded: 51.45s\n",
      "Total Records: 4432533\n"
     ]
    }
   ],
   "source": [
    "#//*** Input_filename: Comments to Process.\n",
    "#//*** This will eventually be a list of files\n",
    "#input_filename  =\".\\\\data\\\\wallstreetbets_comments.csv.zip\"\n",
    "interval=\"daily\"\n",
    "\n",
    "#//*** Path to processed files\n",
    "#output_filename = f\"./data/processed_reddit_v4_{interval}.csv.zip\"\n",
    "output_filename = f\"./ignore_folder/training_amc_{interval}.csv\"\n",
    "\n",
    "#//*** Path to the stock ticker JSON file\n",
    "stock_ticker_filename = \"./data/stock_tickers.json\"\n",
    "\n",
    "#//*** Convert Path to Mac formatting if needed\n",
    "#if platform.system() == 'Darwin':\n",
    "#    output_filename = output_filename.replace(\"\\\\\",\"/\")\n",
    "#    stock_ticker_filename = stock_ticker_filename.replace(\"\\\\\",\"/\")\n",
    "\n",
    "#//*** Load the Stock Tickers\n",
    "f = open(stock_ticker_filename, \"r\")\n",
    "symbols = json.loads(f.read())['symbols']\n",
    "\n",
    "symbols = [\"amc\"]\n",
    "f.close()\n",
    "\n",
    "process_tfidf = False\n",
    "\n",
    "print(symbols)\n",
    "#//*** Convert symbols to lower case\n",
    "symbols = [x.lower() for x in symbols]\n",
    "\n",
    "\n",
    "\n",
    "raw_df = pd.DataFrame()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#//*** Load each Subreddit for Aggregation\n",
    "for subreddit in subreddits:\n",
    "    #//*** Filepath + subreddit name + csv.zip\n",
    "    input_filename = filepath+subreddit+filename_suffix\n",
    "\n",
    "    #//*** Convert Path to Mac formatting if needed\n",
    "    #if platform.system() == 'Darwin':\n",
    "    #    input_filename = input_filename.replace(\"\\\\\",\"/\")\n",
    "   \n",
    "    print(f\"Reading Compressed CSV: {input_filename}\")\n",
    "    \n",
    "    #//*** Read Each DataFrame and combine with raw_df\n",
    "    raw_df = pd.concat([raw_df,pd.read_csv(input_filename,compression='zip' )])\n",
    "\n",
    "#//*** Reset the index, since multiple indexes have been combined\n",
    "raw_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Files Loaded: {round(time.time()-start_time,2)}s\")\n",
    "print(f\"Total Records: {len(raw_df)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-04-11 09:46:43</td>\n",
       "      <td>This is a fantastic idea! I'll toss mine up in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-11 10:39:08</td>\n",
       "      <td>INTC is on 4/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-04-11 11:02:31</td>\n",
       "      <td>straddle, call, straddle, put, put, put, strad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-11 11:47:11</td>\n",
       "      <td>GMCR falls, GOOG falls *slightly*, GRPN will g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-04-11 12:44:33</td>\n",
       "      <td>CROX 4/26\\n\\nBZH 5/1\\n\\ni'm expecting both to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432528</th>\n",
       "      <td>2021-06-30 18:34:33</td>\n",
       "      <td>Jun 30, 9.30pm EST.\\n\\n  \\nI just saw this pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432529</th>\n",
       "      <td>2021-06-30 19:08:36</td>\n",
       "      <td>Good run through. The mill is running and we‚Äôr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432530</th>\n",
       "      <td>2021-06-30 20:11:10</td>\n",
       "      <td>Back to normal not there yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432531</th>\n",
       "      <td>2021-06-30 20:16:51</td>\n",
       "      <td>üíéüëêüöÄüöÄüöÄüöÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432532</th>\n",
       "      <td>2021-06-30 20:40:35</td>\n",
       "      <td>I'll accept that.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4432533 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_utc                                               body\n",
       "0       2012-04-11 09:46:43  This is a fantastic idea! I'll toss mine up in...\n",
       "1       2012-04-11 10:39:08                                    INTC is on 4/17\n",
       "2       2012-04-11 11:02:31  straddle, call, straddle, put, put, put, strad...\n",
       "3       2012-04-11 11:47:11  GMCR falls, GOOG falls *slightly*, GRPN will g...\n",
       "4       2012-04-11 12:44:33  CROX 4/26\\n\\nBZH 5/1\\n\\ni'm expecting both to ...\n",
       "...                     ...                                                ...\n",
       "4432528 2021-06-30 18:34:33  Jun 30, 9.30pm EST.\\n\\n  \\nI just saw this pos...\n",
       "4432529 2021-06-30 19:08:36  Good run through. The mill is running and we‚Äôr...\n",
       "4432530 2021-06-30 20:11:10                       Back to normal not there yet\n",
       "4432531 2021-06-30 20:16:51                                             üíéüëêüöÄüöÄüöÄüöÄ\n",
       "4432532 2021-06-30 20:40:35                                  I'll accept that.\n",
       "\n",
       "[4432533 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['body'] = raw_df['body'].astype('str')\n",
    "\n",
    "#//*** Convert UTC to date (not datetime)\n",
    "#//** Second pass goes from 12-21 to 4-19\n",
    "try:\n",
    "    raw_df['created_utc'] = raw_df['created_utc'].apply(lambda x: datetime.fromtimestamp(x))\n",
    "except:\n",
    "    print()\n",
    "    \n",
    "#//*** Keep just date and body fields\n",
    "raw_df = raw_df[['created_utc','body']]\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-04-11 09:46:43</td>\n",
       "      <td>This is a fantastic idea! I'll toss mine up in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-11 10:39:08</td>\n",
       "      <td>INTC is on 4/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-04-11 11:02:31</td>\n",
       "      <td>straddle, call, straddle, put, put, put, strad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-11 11:47:11</td>\n",
       "      <td>GMCR falls, GOOG falls *slightly*, GRPN will g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-04-11 12:44:33</td>\n",
       "      <td>CROX 4/26\\n\\nBZH 5/1\\n\\ni'm expecting both to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432528</th>\n",
       "      <td>2021-06-30 18:34:33</td>\n",
       "      <td>Jun 30, 9.30pm EST.\\n\\n  \\nI just saw this pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432529</th>\n",
       "      <td>2021-06-30 19:08:36</td>\n",
       "      <td>Good run through. The mill is running and we‚Äôr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432530</th>\n",
       "      <td>2021-06-30 20:11:10</td>\n",
       "      <td>Back to normal not there yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432531</th>\n",
       "      <td>2021-06-30 20:16:51</td>\n",
       "      <td>üíéüëêüöÄüöÄüöÄüöÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432532</th>\n",
       "      <td>2021-06-30 20:40:35</td>\n",
       "      <td>I'll accept that.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4432533 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_utc                                               body\n",
       "0       2012-04-11 09:46:43  This is a fantastic idea! I'll toss mine up in...\n",
       "1       2012-04-11 10:39:08                                    INTC is on 4/17\n",
       "2       2012-04-11 11:02:31  straddle, call, straddle, put, put, put, strad...\n",
       "3       2012-04-11 11:47:11  GMCR falls, GOOG falls *slightly*, GRPN will g...\n",
       "4       2012-04-11 12:44:33  CROX 4/26\\n\\nBZH 5/1\\n\\ni'm expecting both to ...\n",
       "...                     ...                                                ...\n",
       "4432528 2021-06-30 18:34:33  Jun 30, 9.30pm EST.\\n\\n  \\nI just saw this pos...\n",
       "4432529 2021-06-30 19:08:36  Good run through. The mill is running and we‚Äôr...\n",
       "4432530 2021-06-30 20:11:10                       Back to normal not there yet\n",
       "4432531 2021-06-30 20:16:51                                             üíéüëêüöÄüöÄüöÄüöÄ\n",
       "4432532 2021-06-30 20:40:35                                  I'll accept that.\n",
       "\n",
       "[4432533 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\family\\anaconda3\\envs\\plaidml\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>amc</td>\n",
       "      <td>22.73</td>\n",
       "      <td>23.71</td>\n",
       "      <td>21.91</td>\n",
       "      <td>23.60</td>\n",
       "      <td>581500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>amc</td>\n",
       "      <td>23.88</td>\n",
       "      <td>24.01</td>\n",
       "      <td>23.51</td>\n",
       "      <td>23.59</td>\n",
       "      <td>305200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>amc</td>\n",
       "      <td>23.66</td>\n",
       "      <td>23.94</td>\n",
       "      <td>22.17</td>\n",
       "      <td>22.41</td>\n",
       "      <td>264700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>amc</td>\n",
       "      <td>22.45</td>\n",
       "      <td>22.63</td>\n",
       "      <td>22.02</td>\n",
       "      <td>22.51</td>\n",
       "      <td>191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>amc</td>\n",
       "      <td>22.44</td>\n",
       "      <td>22.65</td>\n",
       "      <td>21.68</td>\n",
       "      <td>22.30</td>\n",
       "      <td>367100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>amc</td>\n",
       "      <td>57.98</td>\n",
       "      <td>58.76</td>\n",
       "      <td>55.66</td>\n",
       "      <td>56.70</td>\n",
       "      <td>80351219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>amc</td>\n",
       "      <td>55.75</td>\n",
       "      <td>56.29</td>\n",
       "      <td>52.97</td>\n",
       "      <td>54.06</td>\n",
       "      <td>77596927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>amc</td>\n",
       "      <td>55.10</td>\n",
       "      <td>59.36</td>\n",
       "      <td>54.33</td>\n",
       "      <td>58.11</td>\n",
       "      <td>99310240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>amc</td>\n",
       "      <td>59.06</td>\n",
       "      <td>61.00</td>\n",
       "      <td>56.18</td>\n",
       "      <td>56.43</td>\n",
       "      <td>63604135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>amc</td>\n",
       "      <td>56.00</td>\n",
       "      <td>58.18</td>\n",
       "      <td>54.65</td>\n",
       "      <td>56.68</td>\n",
       "      <td>59020626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1818 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time symbol   open   high    low  close    volume\n",
       "0    2014-04-11    amc  22.73  23.71  21.91  23.60    581500\n",
       "1    2014-04-14    amc  23.88  24.01  23.51  23.59    305200\n",
       "2    2014-04-15    amc  23.66  23.94  22.17  22.41    264700\n",
       "3    2014-04-16    amc  22.45  22.63  22.02  22.51    191000\n",
       "4    2014-04-17    amc  22.44  22.65  21.68  22.30    367100\n",
       "...         ...    ...    ...    ...    ...    ...       ...\n",
       "1813 2021-06-24    amc  57.98  58.76  55.66  56.70  80351219\n",
       "1814 2021-06-25    amc  55.75  56.29  52.97  54.06  77596927\n",
       "1815 2021-06-28    amc  55.10  59.36  54.33  58.11  99310240\n",
       "1816 2021-06-29    amc  59.06  61.00  56.18  56.43  63604135\n",
       "1817 2021-06-30    amc  56.00  58.18  54.65  56.68  59020626\n",
       "\n",
       "[1818 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for symbol in symbols:\n",
    "    stock_df = pd.read_csv(f\"./stocks/{symbol}_{interval}.csv.zip\")\n",
    "    stock_df\n",
    "    \n",
    "    if 'date' in stock_df.columns:\n",
    "        stock_df['date'] = pd.to_datetime(stock_df['date'])\n",
    "        stock_df = stock_df.rename(columns={'date':'time'})\n",
    "    else:\n",
    "        stock_df['time'] = pd.to_datetime(stock_df['time'])\n",
    "    \n",
    "    #//*** Keeping this cool chunk of code as a reference\n",
    "    #stock_df['time'] = stock_df['time'].apply(lambda x: x.timestamp())\n",
    "    \n",
    "    #//*** Remove Comments older than the first stock price\n",
    "    raw_df = raw_df[ raw_df['created_utc'] >= stock_df['time'].min() ]\n",
    "    \n",
    "    #//*** Remove Stock Prices older than the first Comments price\n",
    "    stock_df = stock_df[ stock_df['time'] >= raw_df['created_utc'].min() ]\n",
    "    \n",
    "    #//*** Remove Stock Prices older than the last Comments\n",
    "    stock_df = stock_df[ stock_df['time'] <= raw_df['created_utc'].max() ]\n",
    "    \n",
    "    #//*** Reorder Comments by date\n",
    "    raw_df.sort_values('created_utc',inplace=True,ignore_index=True)\n",
    "    \n",
    "    #//*** Reorder Stocks by date\n",
    "    stock_df.sort_values('time',inplace=True, ignore_index=True)\n",
    "stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>amc</td>\n",
       "      <td>22.73</td>\n",
       "      <td>23.71</td>\n",
       "      <td>21.91</td>\n",
       "      <td>23.60</td>\n",
       "      <td>581500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>amc</td>\n",
       "      <td>23.88</td>\n",
       "      <td>24.01</td>\n",
       "      <td>23.51</td>\n",
       "      <td>23.59</td>\n",
       "      <td>305200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>amc</td>\n",
       "      <td>23.66</td>\n",
       "      <td>23.94</td>\n",
       "      <td>22.17</td>\n",
       "      <td>22.41</td>\n",
       "      <td>264700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>amc</td>\n",
       "      <td>22.45</td>\n",
       "      <td>22.63</td>\n",
       "      <td>22.02</td>\n",
       "      <td>22.51</td>\n",
       "      <td>191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>amc</td>\n",
       "      <td>22.44</td>\n",
       "      <td>22.65</td>\n",
       "      <td>21.68</td>\n",
       "      <td>22.30</td>\n",
       "      <td>367100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>amc</td>\n",
       "      <td>57.98</td>\n",
       "      <td>58.76</td>\n",
       "      <td>55.66</td>\n",
       "      <td>56.70</td>\n",
       "      <td>80351219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>amc</td>\n",
       "      <td>55.75</td>\n",
       "      <td>56.29</td>\n",
       "      <td>52.97</td>\n",
       "      <td>54.06</td>\n",
       "      <td>77596927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>amc</td>\n",
       "      <td>55.10</td>\n",
       "      <td>59.36</td>\n",
       "      <td>54.33</td>\n",
       "      <td>58.11</td>\n",
       "      <td>99310240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>amc</td>\n",
       "      <td>59.06</td>\n",
       "      <td>61.00</td>\n",
       "      <td>56.18</td>\n",
       "      <td>56.43</td>\n",
       "      <td>63604135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>amc</td>\n",
       "      <td>56.00</td>\n",
       "      <td>58.18</td>\n",
       "      <td>54.65</td>\n",
       "      <td>56.68</td>\n",
       "      <td>59020626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1818 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time symbol   open   high    low  close    volume\n",
       "0    2014-04-11    amc  22.73  23.71  21.91  23.60    581500\n",
       "1    2014-04-14    amc  23.88  24.01  23.51  23.59    305200\n",
       "2    2014-04-15    amc  23.66  23.94  22.17  22.41    264700\n",
       "3    2014-04-16    amc  22.45  22.63  22.02  22.51    191000\n",
       "4    2014-04-17    amc  22.44  22.65  21.68  22.30    367100\n",
       "...         ...    ...    ...    ...    ...    ...       ...\n",
       "1813 2021-06-24    amc  57.98  58.76  55.66  56.70  80351219\n",
       "1814 2021-06-25    amc  55.75  56.29  52.97  54.06  77596927\n",
       "1815 2021-06-28    amc  55.10  59.36  54.33  58.11  99310240\n",
       "1816 2021-06-29    amc  59.06  61.00  56.18  56.43  63604135\n",
       "1817 2021-06-30    amc  56.00  58.18  54.65  56.68  59020626\n",
       "\n",
       "[1818 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Group the stock values by time, this is essentially like itterrows()\n",
    "groups = stock_df.groupby('time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bec285406772>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#if len(cdf[ (cdf['created_utc'] > t1) & (cdf['created_utc'] < t2) ]) > 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#temp_df = cdf.iloc[min_index:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'created_utc'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'created_utc'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\plaidml\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\plaidml\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__ge__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__ge__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__ge__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# -------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\plaidml\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5500\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5501\u001b[1;33m             \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5503\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\plaidml\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    268\u001b[0m     ):\n\u001b[0;32m    269\u001b[0m         \u001b[1;31m# Call the method on lvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\plaidml\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\plaidml\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__ge__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__ge__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__ge__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# -------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\plaidml\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[0mo_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_isnan\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mo_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0mnat_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mne\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\plaidml\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36m_isnan\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0meach\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m         \"\"\"\n\u001b[1;32m--> 841\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masi8\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0miNaT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m  \u001b[1;31m# NB: override with cache_readonly in immutable subclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cdf = raw_df.copy()\n",
    "\n",
    "#https://www.geeksforgeeks.org/how-to-iterate-over-dataframe-groups-in-python-pandas/\n",
    "key_list = list(groups.groups.keys())\n",
    "\n",
    "bin_df = pd.DataFrame()\n",
    "\n",
    "start_time = time.time()\n",
    "comment_min_time = raw_df['created_utc'].min()\n",
    "comment_max_time = raw_df['created_utc'].max()\n",
    "min_index = 0\n",
    "start_time = time.time()\n",
    "print(\"Processing...\")\n",
    "for x in range(len(key_list)-1):\n",
    "    \n",
    "    #//*** Get a single line of stocks as a dataframe\n",
    "    loop_stocks_df = groups.get_group((key_list)[x]).copy()  \n",
    "    \n",
    "    t1 = groups.get_group((key_list)[x])['time'].iloc[0]\n",
    "    t2 = groups.get_group((key_list)[x+1])['time'].iloc[0]\n",
    "    \n",
    "    #search through cdf to find comments that are between t1 and t2\n",
    "    #if len(cdf[ (cdf['created_utc'] > t1) & (cdf['created_utc'] < t2) ]) > 0:\n",
    "    #temp_df = cdf.iloc[min_index:]\n",
    "    temp_df = cdf[(cdf['created_utc'] >= t1) & (cdf['created_utc'] < t2) ]\n",
    "    \n",
    "    if len(temp_df) == 0:\n",
    "            #//*** No COmments on this Date\n",
    "            loop_stocks_df['body'] = \" \"\n",
    "            loop_stocks_df['comment_count'] = 0\n",
    "    else:\n",
    "        #print(temp_df.index[0])\n",
    "        #print(temp_df.index[-1])\n",
    "        #print(cdf.iloc[temp_df.index[0]:temp_df.index[-1]])\n",
    "        temp_df = cdf.iloc[temp_df.index[0]:temp_df.index[-1]]\n",
    "        #//*** Get all the body comments and combine them\n",
    "        loop_stocks_df['body'] = \" \".join(list(temp_df['body']))\n",
    "\n",
    "        #//*** Get a comment count, BC IDK Y\n",
    "        loop_stocks_df['comment_count'] = len(temp_df['body']) \n",
    "    \n",
    "    #//*** Secret to speeding up algorithm. Get the Index value of the last item found -1. \n",
    "    #//*** When Searching above, start the search from this index. Seems to speed things up. Since we're skipping past elements that we've already found\n",
    "    if len(temp_df) > 0: \n",
    "        min_index = temp_df.index[-1]\n",
    "\n",
    "        \n",
    "    \n",
    "    #//*** Add the single line of loop_stocks_df to bin_df    \n",
    "    bin_df = pd.concat([bin_df,loop_stocks_df])\n",
    "        #print(loop_df.index)\n",
    "        #print(loop_df)\n",
    "        #cdf = cdf.drop(index=loop_df.index)\n",
    "    \n",
    "        \n",
    "    \n",
    "    #lengroup\n",
    "   \n",
    "    #if x > 1000:\n",
    "    #    bin_df.head(20)\n",
    "    #    print(\"break\")\n",
    "    #    break\n",
    "print(f\"Elapsed {round(time.time()-start_time,2)}\")\n",
    "\n",
    "#print(\"Merging\")\n",
    "#bin_df = pd.merge(bin_df,stock_df,left_on='bin_time',right_on='time')\n",
    "\n",
    "#del bin_df['bin_time']\n",
    "#print(bin_df)\n",
    "print(\"Pickling\")\n",
    "\n",
    "#bin_df.to_pickle(output_filename,compression='zip')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = bin_df[bin_df['time'] >= pd.to_datetime(\"2020-01-01\")]\n",
    "tdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(bin_df['time'],bin_df['comment_count'] )\n",
    "\n",
    "\n",
    "\n",
    "    #plt.legend(loc='upper right',bbox_to_anchor=(1.35, 1.2))\n",
    "plt.show()\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(tdf['time'],tdf['comment_count'] )\n",
    "\n",
    "\n",
    "\n",
    "    #plt.legend(loc='upper right',bbox_to_anchor=(1.35, 1.2))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//***Aggreate Comments for Training\n",
    "#//*** Build tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#loop_list.append(tfidf.fit_transform(input_df['tfidf']))\n",
    "tfidf_matrix = []\n",
    "tfidf_list = []\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "print(\"Starting tfidf....\")\n",
    "start_time = time.time()\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(tdf['body'])\n",
    "\n",
    "\n",
    "print(f\"Built: {round(time.time()-start_time,2)}\")\n",
    "\n",
    "print(tfidf_matrix)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Build TruncatedSVD\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Begin Truncated SVD \")\n",
    "\n",
    "\n",
    "#//*** Set the number of components to 6000. This is generating 98% variance capture\n",
    "#//*** 60min data set took around 25minutes to build\n",
    "tsvd = TruncatedSVD(1000)\n",
    "tsvd_df = pd.DataFrame(tsvd.fit_transform(tfidf_matrix))\n",
    "print(tsvd.explained_variance_ratio_.sum())\n",
    "\n",
    "#print (f\"Truncated SVD Done: {round(time.time()-start_time,2)}s\")\n",
    "#output_filename = './ignore_folder/tsvd_model_ready_daily.csv.zip'\n",
    "#//*** Write Truncated SVD to disk\n",
    "#tsvd_df.to_csv(output_filename, compression='zip', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offset_target = 1\n",
    "\n",
    "#/***Reorder and drop tdf columns\n",
    "tdf = tdf[['close','volume','open','high','low','comment_count','time']]\n",
    "tdf.reset_index(drop=True, inplace=True)\n",
    "start_time = time.time()\n",
    "print(f\"Begin Concat\")\n",
    "df = pd.concat([tdf,pd.DataFrame(tfidf_matrix.toarray())],axis=1)\n",
    "print (f\"Concat Done: {round(time.time()-start_time,2)}s\")\n",
    "#del df['body']\n",
    "#del df['symbol']\n",
    "#start_time = time.time()\n",
    "#print(f\"Writing to csv\")\n",
    "#output_filename = f\"./ignore_folder/training_amc_{interval}.csv.zip\"\n",
    "#tdf.to_csv(output_filename,index=False)\n",
    "#print (f\"Written: {round(time.time()-start_time,2)}s\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Building Target Offset Columns...\")\n",
    "#//*** Build the target variables and intervals of stock prices. This is a single value determined by target)offset\n",
    "\n",
    "#//*** create a list of nan values of x length\n",
    "nan_list = list(np.empty( offset_target )* np.nan )\n",
    "\n",
    "#//*** Create target variable Price which is stocks + x columns in advance\n",
    "#//*** Takes the closing price starting at x and gets the remainder, this generates the offset\n",
    "#//*** nan_list fills the missing x values with nans\n",
    "target = list(df['close'][offset_target:]) + nan_list \n",
    "target = target[:offset_target*-1]\n",
    "print(len(target))\n",
    "df = df[:offset_target*-1]\n",
    "print(df.shape)\n",
    "\n",
    "print(f\"Building Time Series\")\n",
    "#//*** Peel off Time. Used for graphing\n",
    "time_series = df['time']\n",
    "print(len(time_series))\n",
    "del df['time']\n",
    "t_cols = df.columns[:10]\n",
    "df[t_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "#//*** Verify Plaid ML is working\n",
    "import plaidml.keras\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "plaidml.keras.install_backend()\n",
    "\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.RMSprop(0.0099)\n",
    "#create and fit the Regression network\n",
    "def model_regr(dim_size,lrn_rate = 0.01, mntum = 0 ):\n",
    "    #Intializing the RNN\n",
    "    model = Sequential()\n",
    "    #1st layer\n",
    "    model.add(layers.Dense(500, activation='relu', input_shape=(dim_size,)))\n",
    "    model.add(layers.Dense(250, activation='relu', input_shape=(dim_size,)))\n",
    "    model.add(layers.Dense(125, activation='relu', input_shape=(dim_size,)))\n",
    "    model.add(layers.Dense(50, activation='relu', input_shape=(dim_size,)))\n",
    "    #network.add(layers.Dense(32, activation='relu'))\n",
    "    #network.add(layers.Dense(1))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #2nd layer\n",
    "    #model.add(layers.Dense(dim_size, activation='relu'))\n",
    "    #network.add(layers.Dense(dim_size, activation='relu'))\n",
    "    #network.add(layers.Dense(dim_size, activation='relu'))\n",
    "    #network.add(layers.Dense(dim_size/4, activation='relu'))\n",
    "    #network.add(layers.Dense(dim_size/8, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #Adding the output layer\n",
    "    model.add(layers.Dense(1))\n",
    "    #model.compile(loss = 'mse', optimizer='adam', metrics=['mse','mae','mape'])\n",
    "    #model.compile(loss = 'mse', optimizer='RMSprop', metrics=['mse','mae','mape'])\n",
    "    model.compile(loss = 'mse', optimizer='adam', metrics=['mse','mae','mape'])\n",
    "    return model\n",
    "\n",
    "X,y = np.array(df), np.array(target)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.33, shuffle=False)\n",
    "#x_train =     np.array(df[:180])\n",
    "#y_train = np.array(target[:180])\n",
    "#x_test =     np.array(df[181:200])\n",
    "#y_test = np.array(target[181:200])\n",
    "\n",
    "        #//*** Scale the training data\n",
    "scaler = MinMaxScaler()\n",
    "x_train_norm = scaler.fit_transform(x_train)\n",
    "x_test_norm = scaler.fit_transform(x_test)\n",
    "\n",
    "start_time = time.time()\n",
    "print(x_train.shape[1])\n",
    "regr = model_regr(x_train_norm.shape[1],lrn_rate=0.01, mntum=0)\n",
    "history = regr.fit(x_train, y_train, batch_size=1, verbose=1, epochs=5)\n",
    "print(f\"Run time internal GPU: {time.time()-start_time}\")\n",
    "result = regr.predict(x_test_norm)\n",
    "\n",
    "#//*** Mean Squared error\n",
    "mse = mean_squared_error(y_test, result)\n",
    "#//*** Root Mean squared Error\n",
    "rmse = sqrt(mse)\n",
    "#//*** r2 score for model evaluation\n",
    "r2 = r2_score(y_test,result)\n",
    "\n",
    "print(rmse)\n",
    "print(r2)\n",
    "\n",
    "display_size = 40\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(range(len(y_test)),y_test )\n",
    "ax.scatter(range(len(result)),result,color='red' )\n",
    "\n",
    "\n",
    "    #plt.legend(loc='upper right',bbox_to_anchor=(1.35, 1.2))\n",
    "plt.show()\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "for x in history.history.keys():\n",
    "    plt.plot(history.history[x],label=x)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "    plt.title(x)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#This is cool but likely a dead end\n",
    "\n",
    "def recurse_search(needle,haystack):\n",
    "\n",
    "    #print(f\"recurse: {needle} {len(haystack)}\")\n",
    "\n",
    "    if len(haystack) < 10:\n",
    "        #print(\"10 Stack\")\n",
    "        #print(haystack)\n",
    "        return haystack\n",
    "\n",
    "    half_dex = int(len(haystack) / 2)\n",
    "\n",
    "    if needle >= haystack[half_dex]:\n",
    "        return recurse_search(needle,haystack[half_dex:])\n",
    "    else:\n",
    "        return recurse_search(needle,haystack[:half_dex])\n",
    "\n",
    "print(\"!\")    \n",
    "def get_bin_time(needle,haystack):\n",
    "    \n",
    "    small_stack = recurse_search(needle,haystack)\n",
    "    for index in range(len(haystack)):\n",
    "        \n",
    "        \n",
    "        if index+1 > len(haystack):\n",
    "            #print(haystack[index])\n",
    "            return haystack[index]\n",
    "\n",
    "        if (needle > haystack[index]):\n",
    "            if needle < haystack[index+1]: \n",
    "               # print(f\"{index}:{len(haystack)} [{haystack[index]} > {needle} < {haystack[index+1]}]\")\n",
    "\n",
    "                return haystack[index]\n",
    "\n",
    "    \n",
    "\n",
    "#//*** Bin comments into times centered around pricing\n",
    "bin_time = []\n",
    "print(\"Binning Times\")\n",
    "start_time = time.time()\n",
    "#raw_df['bin_time'] = raw_df['created_utc'].sort_values().apply(lambda x: get_bin_time(x,stock_times))\n",
    "\n",
    "\n",
    "for x in comment_times:\n",
    "    \n",
    "    bin_time.append(get_bin_time(x,stock_times))\n",
    "    if len(bin_time) > 100000:\n",
    "        break\n",
    "print(f\"Binned {round(time.time()-start_time,2)}\")\n",
    "    \n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
