{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import stoneburner\n",
    "#//*** Custom Functions:\n",
    "#//*** mr_clean_text(input_series)\n",
    "\n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#//*** Use the whole window in the IPYNB editor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#//*** Maximize columns and rows displayed by pandas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Compressed CSV\n",
      "File Loaded: 2.31s\n",
      "remove_empty False\n",
      "Text Cleaning Time: 3.221360206604004\n",
      "Tokenize Time: 35.08228659629822\n",
      "Stop Words Time: 6.15438985824585\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>body</th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>stickied</th>\n",
       "      <th>permalink</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>hash</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>I will accept payments for my research...what'...</td>\n",
       "      <td>c5y9v5z</td>\n",
       "      <td>t3_yqtpn</td>\n",
       "      <td>t1_c5y49wz</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429727e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>77c0f32dcf506571815f3d4839454f2b3e550f0e1efecd...</td>\n",
       "      <td>[will, accept, payments, my, research, whats, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_4p1mf</td>\n",
       "      <td>Because previously (until this post), when som...</td>\n",
       "      <td>c5yaaki</td>\n",
       "      <td>t3_yqtpn</td>\n",
       "      <td>t1_c5y9v5z</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429728e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>b61949552c3a5d559111ba44d17a71113e408126dd198d...</td>\n",
       "      <td>[previously, post, someone, claimed, looking, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>So you thought I was just going to give all of...</td>\n",
       "      <td>c5yahuo</td>\n",
       "      <td>t3_yqtpn</td>\n",
       "      <td>t1_c5yaaki</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429728e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>97bf3c55f77337de3d6b83b05fc5601e2b346845b7b778...</td>\n",
       "      <td>[thought, was, going, give, research, time, aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_3o5bc</td>\n",
       "      <td>I would also see some proof to back up your cl...</td>\n",
       "      <td>c5yaloj</td>\n",
       "      <td>t3_yqtpn</td>\n",
       "      <td>t1_c5y7jem</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429728e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>5a3885658ca462a1fc0dd3b0af8858e183b05f4f474b84...</td>\n",
       "      <td>[would, also, see, proof, back, claims, your, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_4p1mf</td>\n",
       "      <td>&amp;gt; So you thought I was just going to give a...</td>\n",
       "      <td>c5yamfs</td>\n",
       "      <td>t3_yqtpn</td>\n",
       "      <td>t1_c5yahuo</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429728e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>405314aad1e814100e822f7ac89274b17d66c4e11e5521...</td>\n",
       "      <td>[because, post, chart, their, site, do, includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399863</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_9z0opsh3</td>\n",
       "      <td>Nice</td>\n",
       "      <td>h32dw7m</td>\n",
       "      <td>t3_o7jx7p</td>\n",
       "      <td>t1_h329ycg</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/o7jx7p/fraternal_as...</td>\n",
       "      <td>1.624958e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>fdc96ffbf256523aec8846ae56321053c7ab751c99eb76...</td>\n",
       "      <td>[nice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399864</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_qc6iq</td>\n",
       "      <td>Ah so horoscopes ARE real</td>\n",
       "      <td>h32dwab</td>\n",
       "      <td>t3_o7z71d</td>\n",
       "      <td>t3_o7z71d</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/o7z71d/amc_what_hap...</td>\n",
       "      <td>1.624958e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>20c5bee31dc23c8937aea64670a4157c6547621f763ff4...</td>\n",
       "      <td>[ah, horoscopes, real]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399865</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_bl7b6dkh</td>\n",
       "      <td>If one did this I would tell them Fuck Outta Here</td>\n",
       "      <td>h32dwip</td>\n",
       "      <td>t3_o7vagy</td>\n",
       "      <td>t1_h32daow</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/o7vagy/weekend_disc...</td>\n",
       "      <td>1.624958e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>96ac9390a4f9c8c36aeabf6d3f0358478ce7b3a295c9b6...</td>\n",
       "      <td>[one, this, would, tell, fuck, outta]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399866</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_5b0a37kn</td>\n",
       "      <td>Canada has still those stupid Covid restrictio...</td>\n",
       "      <td>h32dwhz</td>\n",
       "      <td>t3_o7vagy</td>\n",
       "      <td>t3_o7vagy</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/o7vagy/weekend_disc...</td>\n",
       "      <td>1.624958e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>6fa28767c5b75399225dd168a981c8570422fab812afab...</td>\n",
       "      <td>[canada, still, stupid, covid, restrictions, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399867</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_f7cphdq</td>\n",
       "      <td>Go fuck yourself with a cactus. It’s the weeke...</td>\n",
       "      <td>h32dwt5</td>\n",
       "      <td>t3_o7vagy</td>\n",
       "      <td>t1_h32dsig</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/o7vagy/weekend_disc...</td>\n",
       "      <td>1.624958e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>5a9d2e286476b7403cb72369dd669ab680d5380add5ffd...</td>\n",
       "      <td>[go, fuck, with, cactus, the, weekend, fuck, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399868 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        score  total_awards_received created_utc  is_submitter  \\\n",
       "0           1                    0.0  2012-08-24         False   \n",
       "1           3                    0.0  2012-08-24         False   \n",
       "2          -2                    0.0  2012-08-24         False   \n",
       "3           2                    0.0  2012-08-24         False   \n",
       "4           2                    0.0  2012-08-24         False   \n",
       "...       ...                    ...         ...           ...   \n",
       "399863      3                    0.0  2021-06-25         False   \n",
       "399864      3                    0.0  2021-06-25         False   \n",
       "399865      3                    0.0  2021-06-25         False   \n",
       "399866      4                    0.0  2021-06-25         False   \n",
       "399867      6                    0.0  2021-06-25         False   \n",
       "\n",
       "       author_fullname                                               body  \\\n",
       "0                    0  I will accept payments for my research...what'...   \n",
       "1             t2_4p1mf  Because previously (until this post), when som...   \n",
       "2                    0  So you thought I was just going to give all of...   \n",
       "3             t2_3o5bc  I would also see some proof to back up your cl...   \n",
       "4             t2_4p1mf  &gt; So you thought I was just going to give a...   \n",
       "...                ...                                                ...   \n",
       "399863     t2_9z0opsh3                                               Nice   \n",
       "399864        t2_qc6iq                          Ah so horoscopes ARE real   \n",
       "399865     t2_bl7b6dkh  If one did this I would tell them Fuck Outta Here   \n",
       "399866     t2_5b0a37kn  Canada has still those stupid Covid restrictio...   \n",
       "399867      t2_f7cphdq  Go fuck yourself with a cactus. It’s the weeke...   \n",
       "\n",
       "             id    link_id   parent_id  stickied  \\\n",
       "0       c5y9v5z   t3_yqtpn  t1_c5y49wz     False   \n",
       "1       c5yaaki   t3_yqtpn  t1_c5y9v5z     False   \n",
       "2       c5yahuo   t3_yqtpn  t1_c5yaaki     False   \n",
       "3       c5yaloj   t3_yqtpn  t1_c5y7jem     False   \n",
       "4       c5yamfs   t3_yqtpn  t1_c5yahuo     False   \n",
       "...         ...        ...         ...       ...   \n",
       "399863  h32dw7m  t3_o7jx7p  t1_h329ycg     False   \n",
       "399864  h32dwab  t3_o7z71d   t3_o7z71d     False   \n",
       "399865  h32dwip  t3_o7vagy  t1_h32daow     False   \n",
       "399866  h32dwhz  t3_o7vagy   t3_o7vagy     False   \n",
       "399867  h32dwt5  t3_o7vagy  t1_h32dsig     False   \n",
       "\n",
       "                                                permalink  retrieved_on  \\\n",
       "0                                                       0  1.429727e+09   \n",
       "1                                                       0  1.429728e+09   \n",
       "2                                                       0  1.429728e+09   \n",
       "3                                                       0  1.429728e+09   \n",
       "4                                                       0  1.429728e+09   \n",
       "...                                                   ...           ...   \n",
       "399863  /r/wallstreetbets/comments/o7jx7p/fraternal_as...  1.624958e+09   \n",
       "399864  /r/wallstreetbets/comments/o7z71d/amc_what_hap...  1.624958e+09   \n",
       "399865  /r/wallstreetbets/comments/o7vagy/weekend_disc...  1.624958e+09   \n",
       "399866  /r/wallstreetbets/comments/o7vagy/weekend_disc...  1.624958e+09   \n",
       "399867  /r/wallstreetbets/comments/o7vagy/weekend_disc...  1.624958e+09   \n",
       "\n",
       "             subreddit subreddit_id  \\\n",
       "0       wallstreetbets     t5_2th52   \n",
       "1       wallstreetbets     t5_2th52   \n",
       "2       wallstreetbets     t5_2th52   \n",
       "3       wallstreetbets     t5_2th52   \n",
       "4       wallstreetbets     t5_2th52   \n",
       "...                ...          ...   \n",
       "399863  wallstreetbets     t5_2th52   \n",
       "399864  wallstreetbets     t5_2th52   \n",
       "399865  wallstreetbets     t5_2th52   \n",
       "399866  wallstreetbets     t5_2th52   \n",
       "399867  wallstreetbets     t5_2th52   \n",
       "\n",
       "                                                     hash  \\\n",
       "0       77c0f32dcf506571815f3d4839454f2b3e550f0e1efecd...   \n",
       "1       b61949552c3a5d559111ba44d17a71113e408126dd198d...   \n",
       "2       97bf3c55f77337de3d6b83b05fc5601e2b346845b7b778...   \n",
       "3       5a3885658ca462a1fc0dd3b0af8858e183b05f4f474b84...   \n",
       "4       405314aad1e814100e822f7ac89274b17d66c4e11e5521...   \n",
       "...                                                   ...   \n",
       "399863  fdc96ffbf256523aec8846ae56321053c7ab751c99eb76...   \n",
       "399864  20c5bee31dc23c8937aea64670a4157c6547621f763ff4...   \n",
       "399865  96ac9390a4f9c8c36aeabf6d3f0358478ce7b3a295c9b6...   \n",
       "399866  6fa28767c5b75399225dd168a981c8570422fab812afab...   \n",
       "399867  5a9d2e286476b7403cb72369dd669ab680d5380add5ffd...   \n",
       "\n",
       "                                                    clean  \n",
       "0       [will, accept, payments, my, research, whats, ...  \n",
       "1       [previously, post, someone, claimed, looking, ...  \n",
       "2       [thought, was, going, give, research, time, aw...  \n",
       "3       [would, also, see, proof, back, claims, your, ...  \n",
       "4       [because, post, chart, their, site, do, includ...  \n",
       "...                                                   ...  \n",
       "399863                                             [nice]  \n",
       "399864                             [ah, horoscopes, real]  \n",
       "399865              [one, this, would, tell, fuck, outta]  \n",
       "399866  [canada, still, stupid, covid, restrictions, p...  \n",
       "399867  [go, fuck, with, cactus, the, weekend, fuck, t...  \n",
       "\n",
       "[399868 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_filename  =\".\\\\data\\\\wallstreetbets_comments.csv.zip\"\n",
    "output_filename = \".\\\\data\\\\processed_reddit_basic_v1.csv.zip\"\n",
    "\n",
    "#//*** Stock Ticker Symbols to track\n",
    "symbols = [\"CLOV\",\"SOFI\",\"WKHS\",\"AMD\",\"GME\",\"X\",\"AMC\",\"CLNE\",\"NIO\",\"MU\",\"SPCE\",\"BB\"]\n",
    "\n",
    "#//*** Convert symbols to lower case\n",
    "symbols = [x.lower() for x in symbols]\n",
    "    \n",
    "#//*** Load Clean and Prepare data for aggregation\n",
    "start_time = time.time()\n",
    "print(\"Reading Compressed CSV\")\n",
    "raw_df = pd.read_csv(input_filename,compression='zip' )\n",
    "print(f\"File Loaded: {round(time.time()-start_time,2)}s\")\n",
    "\n",
    "#//*** Convert UTC to date (not datetime)\n",
    "#//** Second pass goes from 12-21 to 4-19\n",
    "try:\n",
    "    raw_df['created_utc'] = raw_df['created_utc'].apply(lambda x: date.fromtimestamp(x))\n",
    "except:\n",
    "    print()\n",
    "\n",
    "\n",
    "raw_df['clean'] = stoneburner.remove_stop_words(stoneburner.tokenize_series(stoneburner.mr_clean_text(raw_df['body'],{\"remove_empty\":False})))\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def encode_comments(raw_df):\n",
    "    import time\n",
    "    \n",
    "    print(\"Begin dataframe ticker symbol coding\")\n",
    "    start_time = time.time()\n",
    "       \n",
    "    \n",
    "    \n",
    "    #//*** Count each Stock mention add it to a dictionary of lists. Each list is filled with 0s. The Specific row index is updated with the relevant count. \n",
    "    #//*** This Generates a word count matrix\n",
    "    stock_dict = {}\n",
    "\n",
    "    #//*** Keep Track of Rows\n",
    "    index = 0\n",
    "\n",
    "    for row in raw_df.iterrows():\n",
    "\n",
    "        #//*** Get the cleaned body text\n",
    "        body = row[1]['clean']\n",
    "\n",
    "        #//*** For Each Stock Symbol\n",
    "        for stock in symbols:\n",
    "            \n",
    "            #//*** Check if Stock exists in Body\n",
    "            if stock in body:\n",
    "\n",
    "                #//*** Reset the stock counter\n",
    "                count = 0\n",
    "\n",
    "                #//*** Loop through body and county ticker mentions\n",
    "                for word in body:\n",
    "                    #//*** If word found increment count\n",
    "                    if stock == word:\n",
    "                        count += 1\n",
    "\n",
    "                #//*** Check if symbol is in stock_dict\n",
    "                if stock not in stock_dict.keys():    \n",
    "\n",
    "                    #//*** If not, then build it\n",
    "                    stock_dict[stock] = np.zeros(len(raw_df))\n",
    "\n",
    "                #//*** Update the stock value at the \n",
    "                stock_dict[stock][index] = count\n",
    "\n",
    "        #//*** Increment Index to keep with row index\n",
    "        index +=1   \n",
    "\n",
    "    #//*** Loop through the dictionary key and lists\n",
    "    for col,values in stock_dict.items():\n",
    "\n",
    "        #//*** Add each key (which is a stock ticker symbol) as a column using the list of ticker counts for Data\n",
    "        raw_df[col] = values.astype('int')\n",
    "\n",
    "    print(f\"Encoding Time: {round(time.time()-start_time,2)}s\")\n",
    "    \n",
    "    return raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Encodes the dataframe with a count of Ticker symbols in each comment.\n",
    "#//*** Called from update_subreddit(). This is broken out since we will likely need to adjust encoding parameters\n",
    "def aggregate_comments(input_df):\n",
    "    \n",
    "    to_sum_cols = ['score','total_awards_received']\n",
    "    to_count_col = ['author_fullname','link_id']\n",
    "    \n",
    "    \n",
    "    df_cols = ['date','total_posts']\n",
    "    \n",
    "    rename_cols = {\n",
    "        'total_awards_received' : 'awards',\n",
    "        'author_fullname' : 'authors',\n",
    "        'link_id' : 'threads'\n",
    "    }\n",
    "    \n",
    "    #//*** Build the OUtput Dataframe Column names from the Columns to sum, the columns to count, and the stock ticker columns\n",
    "    #//*** Loop through each list\n",
    "    for cols in [ to_sum_cols, to_count_col, symbols ]:\n",
    "        \n",
    "        #//*** Get individual column name from each column list\n",
    "        for col in cols:\n",
    "            print\n",
    "            #//*** Rename the column if in rename_col\n",
    "            #//*** Add col to df_cols....The out_df column names\n",
    "            if col in rename_cols.keys():\n",
    "                df_cols.append(rename_cols[col])\n",
    "            else:\n",
    "                df_cols.append(col)\n",
    "                \n",
    "    print(df_cols)\n",
    "    \n",
    "    out_df = pd.DataFrame(columns = df_cols)\n",
    "    \n",
    "   \n",
    "    #//*** Group \n",
    "    for group in input_df.groupby('created_utc'):\n",
    "        \n",
    "        loop_df = group[1].copy()\n",
    "        \n",
    "        loop_list = []\n",
    "        \n",
    "        #//*** Build the aggregated row for the Dataframe.\n",
    "        #//*** 4 Parts: \n",
    "        #//******** 1.) Date & Total Posts\n",
    "        #//******** 2.) Columns to sum\n",
    "        #//******** 3.) Columns to count\n",
    "        #//******** 4.) Stock Ticker columns to sum\n",
    "        \n",
    "        #//********************************************\n",
    "        #//******** 1.) Date & Total Posts\n",
    "        #//********************************************\n",
    "        #//*** Add the Date\n",
    "        loop_list.append(group[0])\n",
    "        \n",
    "        #//*** Add Total number of posts\n",
    "        loop_list.append(len(loop_df))\n",
    "        \n",
    "        #//********************************************\n",
    "        #//******** 2.) Columns to sum\n",
    "        #//********************************************\n",
    "        for col in to_sum_cols:\n",
    "            loop_list.append(loop_df[col].sum())\n",
    "\n",
    "            \n",
    "        #//********************************************\n",
    "        #//******** 3.) Columns to count\n",
    "        #//********************************************\n",
    "        for col in to_count_col:\n",
    "            loop_list.append(len(loop_df[col].unique()))\n",
    "    \n",
    "        \n",
    "        #//********************************************\n",
    "        #//******** 4.) Stock Ticker columns to sum\n",
    "        #//********************************************\n",
    "        for col in symbols:\n",
    "            loop_list.append(loop_df[col].sum())\n",
    "\n",
    "        #print(len(out_df.columns),len(loop_list))\n",
    "        #print(out_df.columns)\n",
    "        out_df.loc[len(out_df.index)] = loop_list \n",
    "\n",
    "    return out_df\n",
    "\n",
    "\n",
    "\n",
    "#for col in df.columns[16:]:\n",
    "#    print(df[df[col] > 0 ].iloc[0]['created_utc'],col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin dataframe ticker symbol coding\n",
      "Encoding Time: 19.41s\n",
      "['date', 'total_posts', 'score', 'awards', 'authors', 'threads', 'clov', 'sofi', 'wkhs', 'amd', 'gme', 'x', 'amc', 'clne', 'nio', 'mu', 'spce', 'bb']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_posts</th>\n",
       "      <th>score</th>\n",
       "      <th>awards</th>\n",
       "      <th>authors</th>\n",
       "      <th>threads</th>\n",
       "      <th>clov</th>\n",
       "      <th>sofi</th>\n",
       "      <th>wkhs</th>\n",
       "      <th>amd</th>\n",
       "      <th>gme</th>\n",
       "      <th>x</th>\n",
       "      <th>amc</th>\n",
       "      <th>clne</th>\n",
       "      <th>nio</th>\n",
       "      <th>mu</th>\n",
       "      <th>spce</th>\n",
       "      <th>bb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>29</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-08-26</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-08-27</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-08-28</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2021-06-21</td>\n",
       "      <td>567</td>\n",
       "      <td>2878</td>\n",
       "      <td>8.0</td>\n",
       "      <td>429</td>\n",
       "      <td>89</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>557</td>\n",
       "      <td>3076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>400</td>\n",
       "      <td>113</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2021-06-23</td>\n",
       "      <td>694</td>\n",
       "      <td>4543</td>\n",
       "      <td>7.0</td>\n",
       "      <td>488</td>\n",
       "      <td>118</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>513</td>\n",
       "      <td>2857</td>\n",
       "      <td>5.0</td>\n",
       "      <td>397</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>1017</td>\n",
       "      <td>6312</td>\n",
       "      <td>10.0</td>\n",
       "      <td>543</td>\n",
       "      <td>116</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date total_posts score  awards authors threads clov sofi wkhs amd  \\\n",
       "0    2012-08-24          29    80     0.0      13       6    0    0    0   0   \n",
       "1    2012-08-25          19    18     0.0       7       3    0    0    0   0   \n",
       "2    2012-08-26          13    11     0.0       9       5    0    0    0   0   \n",
       "3    2012-08-27          11    21     0.0       6       6    0    0    0   0   \n",
       "4    2012-08-28           5     9     0.0       4       3    0    0    0   0   \n",
       "..          ...         ...   ...     ...     ...     ...  ...  ...  ...  ..   \n",
       "446  2021-06-21         567  2878     8.0     429      89   10    0    7   4   \n",
       "447  2021-06-22         557  3076     2.0     400     113   14    2    2   5   \n",
       "448  2021-06-23         694  4543     7.0     488     118   21    0   11   3   \n",
       "449  2021-06-24         513  2857     5.0     397      72   18    0   12   4   \n",
       "450  2021-06-25        1017  6312    10.0     543     116   11    2    2   3   \n",
       "\n",
       "    gme  x amc clne nio mu spce  bb  \n",
       "0     0  0   0    0   0  0    0   0  \n",
       "1     0  0   0    0   0  0    0   0  \n",
       "2     0  0   0    0   0  0    0   0  \n",
       "3     0  0   0    0   0  0    0   0  \n",
       "4     0  0   0    0   0  0    0   0  \n",
       "..   .. ..  ..  ...  .. ..  ...  ..  \n",
       "446   9  1  10    7   5  3    0  12  \n",
       "447   8  1  10    7   1  0    0  10  \n",
       "448  12  0   9    3   6  0    3   8  \n",
       "449   1  0   6    3   0  1    1   5  \n",
       "450  14  2  13    7   0  0   28   9  \n",
       "\n",
       "[451 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Encode Comments\n",
    "df = encode_comments(raw_df)\n",
    "\n",
    "#//*** Aggregate and Process Comments\n",
    "ag_df = aggregate_comments(df)\n",
    "ag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Write File to disk\n",
    "\n",
    "ag_df.to_csv(output_filename,compression=\"zip\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
