{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import platform\n",
    "\n",
    "import stoneburner\n",
    "#//*** Custom Functions:\n",
    "#//*** mr_clean_text(input_series)\n",
    "#//*** tokenize_series(input_series)\n",
    "#//*** remove_stop_words(input_series)\n",
    "\n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#//*** Use the whole window in the IPYNB editor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#//*** Maximize columns and rows displayed by pandas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clov', 'sofi', 'wkhs', 'amd', 'gme', 'x', 'amc', 'clne', 'nio', 'mu', 'spce', 'bb']\n",
      "Reading Compressed CSV\n",
      "File Loaded: 3.38s\n",
      "remove_empty False\n",
      "Text Cleaning Time: 4.486855745315552\n",
      "Tokenize Time: 49.75190496444702\n",
      "Stop Words Time: 7.277637481689453\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>body</th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>stickied</th>\n",
       "      <th>permalink</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>hash</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>I will accept payments for my research...what'...</td>\n",
       "      <td>c5y9v5z</td>\n",
       "      <td>t3_yqtpn</td>\n",
       "      <td>t1_c5y49wz</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429727e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>77c0f32dcf506571815f3d4839454f2b3e550f0e1efecd...</td>\n",
       "      <td>[will, accept, payments, my, research, whats, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_4p1mf</td>\n",
       "      <td>Because previously (until this post), when som...</td>\n",
       "      <td>c5yaaki</td>\n",
       "      <td>t3_yqtpn</td>\n",
       "      <td>t1_c5y9v5z</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429728e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>b61949552c3a5d559111ba44d17a71113e408126dd198d...</td>\n",
       "      <td>[previously, post, someone, claimed, looking, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>So you thought I was just going to give all of...</td>\n",
       "      <td>c5yahuo</td>\n",
       "      <td>t3_yqtpn</td>\n",
       "      <td>t1_c5yaaki</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429728e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>97bf3c55f77337de3d6b83b05fc5601e2b346845b7b778...</td>\n",
       "      <td>[thought, was, going, give, research, time, aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_3o5bc</td>\n",
       "      <td>I would also see some proof to back up your cl...</td>\n",
       "      <td>c5yaloj</td>\n",
       "      <td>t3_yqtpn</td>\n",
       "      <td>t1_c5y7jem</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429728e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>5a3885658ca462a1fc0dd3b0af8858e183b05f4f474b84...</td>\n",
       "      <td>[would, also, see, proof, back, claims, your, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_4p1mf</td>\n",
       "      <td>&amp;gt; So you thought I was just going to give a...</td>\n",
       "      <td>c5yamfs</td>\n",
       "      <td>t3_yqtpn</td>\n",
       "      <td>t1_c5yahuo</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.429728e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>405314aad1e814100e822f7ac89274b17d66c4e11e5521...</td>\n",
       "      <td>[because, post, chart, their, site, do, includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399863</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_9z0opsh3</td>\n",
       "      <td>Nice</td>\n",
       "      <td>h32dw7m</td>\n",
       "      <td>t3_o7jx7p</td>\n",
       "      <td>t1_h329ycg</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/o7jx7p/fraternal_as...</td>\n",
       "      <td>1.624958e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>fdc96ffbf256523aec8846ae56321053c7ab751c99eb76...</td>\n",
       "      <td>[nice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399864</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_qc6iq</td>\n",
       "      <td>Ah so horoscopes ARE real</td>\n",
       "      <td>h32dwab</td>\n",
       "      <td>t3_o7z71d</td>\n",
       "      <td>t3_o7z71d</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/o7z71d/amc_what_hap...</td>\n",
       "      <td>1.624958e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>20c5bee31dc23c8937aea64670a4157c6547621f763ff4...</td>\n",
       "      <td>[ah, horoscopes, real]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399865</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_bl7b6dkh</td>\n",
       "      <td>If one did this I would tell them Fuck Outta Here</td>\n",
       "      <td>h32dwip</td>\n",
       "      <td>t3_o7vagy</td>\n",
       "      <td>t1_h32daow</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/o7vagy/weekend_disc...</td>\n",
       "      <td>1.624958e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>96ac9390a4f9c8c36aeabf6d3f0358478ce7b3a295c9b6...</td>\n",
       "      <td>[one, this, would, tell, fuck, outta]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399866</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_5b0a37kn</td>\n",
       "      <td>Canada has still those stupid Covid restrictio...</td>\n",
       "      <td>h32dwhz</td>\n",
       "      <td>t3_o7vagy</td>\n",
       "      <td>t3_o7vagy</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/o7vagy/weekend_disc...</td>\n",
       "      <td>1.624958e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>6fa28767c5b75399225dd168a981c8570422fab812afab...</td>\n",
       "      <td>[canada, still, stupid, covid, restrictions, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399867</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_f7cphdq</td>\n",
       "      <td>Go fuck yourself with a cactus. It’s the weeke...</td>\n",
       "      <td>h32dwt5</td>\n",
       "      <td>t3_o7vagy</td>\n",
       "      <td>t1_h32dsig</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/o7vagy/weekend_disc...</td>\n",
       "      <td>1.624958e+09</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>5a9d2e286476b7403cb72369dd669ab680d5380add5ffd...</td>\n",
       "      <td>[go, fuck, with, cactus, the, weekend, fuck, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399868 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        score  total_awards_received created_utc  is_submitter  \\\n",
       "0           1                    0.0  2012-08-24         False   \n",
       "1           3                    0.0  2012-08-24         False   \n",
       "2          -2                    0.0  2012-08-24         False   \n",
       "3           2                    0.0  2012-08-24         False   \n",
       "4           2                    0.0  2012-08-24         False   \n",
       "...       ...                    ...         ...           ...   \n",
       "399863      3                    0.0  2021-06-25         False   \n",
       "399864      3                    0.0  2021-06-25         False   \n",
       "399865      3                    0.0  2021-06-25         False   \n",
       "399866      4                    0.0  2021-06-25         False   \n",
       "399867      6                    0.0  2021-06-25         False   \n",
       "\n",
       "       author_fullname                                               body  \\\n",
       "0                    0  I will accept payments for my research...what'...   \n",
       "1             t2_4p1mf  Because previously (until this post), when som...   \n",
       "2                    0  So you thought I was just going to give all of...   \n",
       "3             t2_3o5bc  I would also see some proof to back up your cl...   \n",
       "4             t2_4p1mf  &gt; So you thought I was just going to give a...   \n",
       "...                ...                                                ...   \n",
       "399863     t2_9z0opsh3                                               Nice   \n",
       "399864        t2_qc6iq                          Ah so horoscopes ARE real   \n",
       "399865     t2_bl7b6dkh  If one did this I would tell them Fuck Outta Here   \n",
       "399866     t2_5b0a37kn  Canada has still those stupid Covid restrictio...   \n",
       "399867      t2_f7cphdq  Go fuck yourself with a cactus. It’s the weeke...   \n",
       "\n",
       "             id    link_id   parent_id  stickied  \\\n",
       "0       c5y9v5z   t3_yqtpn  t1_c5y49wz     False   \n",
       "1       c5yaaki   t3_yqtpn  t1_c5y9v5z     False   \n",
       "2       c5yahuo   t3_yqtpn  t1_c5yaaki     False   \n",
       "3       c5yaloj   t3_yqtpn  t1_c5y7jem     False   \n",
       "4       c5yamfs   t3_yqtpn  t1_c5yahuo     False   \n",
       "...         ...        ...         ...       ...   \n",
       "399863  h32dw7m  t3_o7jx7p  t1_h329ycg     False   \n",
       "399864  h32dwab  t3_o7z71d   t3_o7z71d     False   \n",
       "399865  h32dwip  t3_o7vagy  t1_h32daow     False   \n",
       "399866  h32dwhz  t3_o7vagy   t3_o7vagy     False   \n",
       "399867  h32dwt5  t3_o7vagy  t1_h32dsig     False   \n",
       "\n",
       "                                                permalink  retrieved_on  \\\n",
       "0                                                       0  1.429727e+09   \n",
       "1                                                       0  1.429728e+09   \n",
       "2                                                       0  1.429728e+09   \n",
       "3                                                       0  1.429728e+09   \n",
       "4                                                       0  1.429728e+09   \n",
       "...                                                   ...           ...   \n",
       "399863  /r/wallstreetbets/comments/o7jx7p/fraternal_as...  1.624958e+09   \n",
       "399864  /r/wallstreetbets/comments/o7z71d/amc_what_hap...  1.624958e+09   \n",
       "399865  /r/wallstreetbets/comments/o7vagy/weekend_disc...  1.624958e+09   \n",
       "399866  /r/wallstreetbets/comments/o7vagy/weekend_disc...  1.624958e+09   \n",
       "399867  /r/wallstreetbets/comments/o7vagy/weekend_disc...  1.624958e+09   \n",
       "\n",
       "             subreddit subreddit_id  \\\n",
       "0       wallstreetbets     t5_2th52   \n",
       "1       wallstreetbets     t5_2th52   \n",
       "2       wallstreetbets     t5_2th52   \n",
       "3       wallstreetbets     t5_2th52   \n",
       "4       wallstreetbets     t5_2th52   \n",
       "...                ...          ...   \n",
       "399863  wallstreetbets     t5_2th52   \n",
       "399864  wallstreetbets     t5_2th52   \n",
       "399865  wallstreetbets     t5_2th52   \n",
       "399866  wallstreetbets     t5_2th52   \n",
       "399867  wallstreetbets     t5_2th52   \n",
       "\n",
       "                                                     hash  \\\n",
       "0       77c0f32dcf506571815f3d4839454f2b3e550f0e1efecd...   \n",
       "1       b61949552c3a5d559111ba44d17a71113e408126dd198d...   \n",
       "2       97bf3c55f77337de3d6b83b05fc5601e2b346845b7b778...   \n",
       "3       5a3885658ca462a1fc0dd3b0af8858e183b05f4f474b84...   \n",
       "4       405314aad1e814100e822f7ac89274b17d66c4e11e5521...   \n",
       "...                                                   ...   \n",
       "399863  fdc96ffbf256523aec8846ae56321053c7ab751c99eb76...   \n",
       "399864  20c5bee31dc23c8937aea64670a4157c6547621f763ff4...   \n",
       "399865  96ac9390a4f9c8c36aeabf6d3f0358478ce7b3a295c9b6...   \n",
       "399866  6fa28767c5b75399225dd168a981c8570422fab812afab...   \n",
       "399867  5a9d2e286476b7403cb72369dd669ab680d5380add5ffd...   \n",
       "\n",
       "                                                    clean  \n",
       "0       [will, accept, payments, my, research, whats, ...  \n",
       "1       [previously, post, someone, claimed, looking, ...  \n",
       "2       [thought, was, going, give, research, time, aw...  \n",
       "3       [would, also, see, proof, back, claims, your, ...  \n",
       "4       [because, post, chart, their, site, do, includ...  \n",
       "...                                                   ...  \n",
       "399863                                             [nice]  \n",
       "399864                             [ah, horoscopes, real]  \n",
       "399865              [one, this, would, tell, fuck, outta]  \n",
       "399866  [canada, still, stupid, covid, restrictions, p...  \n",
       "399867  [go, fuck, with, cactus, the, weekend, fuck, t...  \n",
       "\n",
       "[399868 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Input_filename: Comments to Process.\n",
    "#//*** This will eventually be a list of files\n",
    "input_filename  =\".\\\\data\\\\wallstreetbets_comments.csv.zip\"\n",
    "\n",
    "#//*** Path to processed files\n",
    "output_filename = \".\\\\data\\\\processed_reddit_basic_v2.csv.zip\"\n",
    "\n",
    "#//*** Path to the stock ticker JSON file\n",
    "stock_ticker_filename = \".\\\\data\\\\stock_tickers.json\"\n",
    "\n",
    "#//*** Convert Path to Mac formatting if needed\n",
    "if platform.system() == 'Darwin':\n",
    "    input_filename = input_filename.replace(\"\\\\\",\"/\")\n",
    "    output_filename = output_filename.replace(\"\\\\\",\"/\")\n",
    "    stock_ticker_filename = stock_ticker_filename.replace(\"\\\\\",\"/\")\n",
    "\n",
    "#//*** Load the Stock Tickers\n",
    "f = open(stock_ticker_filename, \"r\")\n",
    "symbols = json.loads(f.read())['symbols']\n",
    "f.close()\n",
    "\n",
    "print(symbols)\n",
    "#//*** Convert symbols to lower case\n",
    "symbols = [x.lower() for x in symbols]\n",
    "\n",
    "    \n",
    "#//*** Load Clean and Prepare data for aggregation\n",
    "start_time = time.time()\n",
    "print(\"Reading Compressed CSV\")\n",
    "raw_df = pd.read_csv(input_filename,compression='zip' )\n",
    "print(f\"File Loaded: {round(time.time()-start_time,2)}s\")\n",
    "\n",
    "#//*** Convert UTC to date (not datetime)\n",
    "#//** Second pass goes from 12-21 to 4-19\n",
    "try:\n",
    "    raw_df['created_utc'] = raw_df['created_utc'].apply(lambda x: date.fromtimestamp(x))\n",
    "except:\n",
    "    print()\n",
    "\n",
    "#//*************************************************************************\n",
    "#//*** Clean the Body Text, Tokenize and Remove Stop Words.\n",
    "#//*************************************************************************\n",
    "raw_df['clean'] = stoneburner.remove_stop_words(stoneburner.tokenize_series(stoneburner.mr_clean_text(raw_df['body'],{\"remove_empty\":False})))\n",
    "\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#//*************************************************************\n",
    "#//*** Load the Encode_comments Function\n",
    "#//*** Counts the Stock mentions in each Post.\n",
    "#//*** Adds the stock as a column to the Dataframe\n",
    "#//*************************************************************\n",
    "\n",
    "def encode_comments(input_df):\n",
    "    import time\n",
    "    \n",
    "    print(\"Begin dataframe ticker symbol coding\")\n",
    "    start_time = time.time()\n",
    "       \n",
    "    \n",
    "    \n",
    "    #//*** Count each Stock mention add it to a dictionary of lists. Each list is filled with 0s. The Specific row index is updated with the relevant count. \n",
    "    #//*** This Generates a word count matrix\n",
    "    stock_dict = {}\n",
    "\n",
    "    #//*** Keep Track of Rows\n",
    "    index = 0\n",
    "\n",
    "    for row in input_df.iterrows():\n",
    "\n",
    "        #//*** Get the cleaned body text\n",
    "        body = row[1]['clean']\n",
    "\n",
    "        #//*** For Each Stock Symbol\n",
    "        for stock in symbols:\n",
    "            \n",
    "            #//*** Check if Stock exists in Body\n",
    "            if stock in body:\n",
    "\n",
    "                #//*** Reset the stock counter\n",
    "                count = 0\n",
    "\n",
    "                #//*** Loop through body and county ticker mentions\n",
    "                for word in body:\n",
    "                    #//*** If word found increment count\n",
    "                    if stock == word:\n",
    "                        count += 1\n",
    "\n",
    "                #//*** Check if symbol is in stock_dict\n",
    "                if stock not in stock_dict.keys():    \n",
    "\n",
    "                    #//*** If not, then build it\n",
    "                    stock_dict[stock] = np.zeros(len(raw_df))\n",
    "\n",
    "                #//*** Update the stock value at the \n",
    "                stock_dict[stock][index] = count\n",
    "\n",
    "        #//*** Increment Index to keep with row index\n",
    "        index +=1   \n",
    "\n",
    "    #//*** Loop through the dictionary key and lists\n",
    "    for col,values in stock_dict.items():\n",
    "\n",
    "        #//*** Add each key (which is a stock ticker symbol) as a column using the list of ticker counts for Data\n",
    "        raw_df[col] = values.astype('int')\n",
    "\n",
    "    print(f\"Encoding Time: {round(time.time()-start_time,2)}s\")\n",
    "    \n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Encodes the dataframe with a count of Ticker symbols in each comment.\n",
    "#//*** Called from update_subreddit(). This is broken out since we will likely need to adjust encoding parameters\n",
    "def aggregate_comments(input_df):\n",
    "    \n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "    to_sum_cols = ['score','total_awards_received']\n",
    "    to_count_col = ['author_fullname','link_id']\n",
    "    \n",
    "    \n",
    "    df_cols = ['date','total_posts','tfidf']\n",
    "    \n",
    "    rename_cols = {\n",
    "        'total_awards_received' : 'awards',\n",
    "        'author_fullname' : 'authors',\n",
    "        'link_id' : 'threads'\n",
    "    }\n",
    "    \n",
    "    #//*** Build the OUtput Dataframe Column names from the Columns to sum, the columns to count, and the stock ticker columns\n",
    "    #//*** Loop through each list\n",
    "    for cols in [ to_sum_cols, to_count_col, symbols ]:\n",
    "        \n",
    "        #//*** Get individual column name from each column list\n",
    "        for col in cols:\n",
    "            print\n",
    "            #//*** Rename the column if in rename_col\n",
    "            #//*** Add col to df_cols....The out_df column names\n",
    "            if col in rename_cols.keys():\n",
    "                df_cols.append(rename_cols[col])\n",
    "            else:\n",
    "                df_cols.append(col)\n",
    "                \n",
    "    print(df_cols)\n",
    "    \n",
    "    out_df = pd.DataFrame(columns = df_cols)\n",
    "    \n",
    "   \n",
    "    #//*** Group \n",
    "    for group in input_df.groupby('created_utc'):\n",
    "        \n",
    "        #//*** Start Timing the process\n",
    "        start_time = time.time()\n",
    "\n",
    "        loop_df = group[1].copy()\n",
    "        \n",
    "        loop_list = []\n",
    "        \n",
    "        #//*** Build the aggregated row for the Dataframe.\n",
    "        #//*** 5 Parts: \n",
    "        #//******** 1.) Date & Total Posts\n",
    "        #//******** 2.) tfidf - Bag of Words for the Day\n",
    "        #//******** 2.) Columns to sum\n",
    "        #//******** 3.) Columns to count\n",
    "        #//******** 4.) Stock Ticker columns to sum\n",
    "        \n",
    "        #//********************************************\n",
    "        #//******** 1.) Date & Total Posts\n",
    "        #//********************************************\n",
    "        #//*** Add the Date\n",
    "        loop_list.append(group[0])\n",
    "        \n",
    "        #//*** Add Total number of posts\n",
    "        loop_list.append(len(loop_df))\n",
    "        \n",
    "        #//********************************************\n",
    "        #//******** 2.) Build tfidf\n",
    "        #//********************************************\n",
    "        \n",
    "        \n",
    "        \n",
    "        #//*** Initialize the Vectorizer\n",
    "        tfidf = TfidfVectorizer()\n",
    "\n",
    "        #//*** Build the feature matrix, which is a weighted sparse matrix\n",
    "        loop_list.append(tfidf.fit_transform(input_df['tfidf']))\n",
    "        \n",
    "        #//********************************************\n",
    "        #//******** 2.) Columns to sum\n",
    "        #//********************************************\n",
    "        for col in to_sum_cols:\n",
    "            loop_list.append(loop_df[col].sum())\n",
    "\n",
    "            \n",
    "        #//********************************************\n",
    "        #//******** 3.) Columns to count\n",
    "        #//********************************************\n",
    "        for col in to_count_col:\n",
    "            loop_list.append(len(loop_df[col].unique()))\n",
    "    \n",
    "        \n",
    "        #//********************************************\n",
    "        #//******** 4.) Stock Ticker columns to sum\n",
    "        #//********************************************\n",
    "        for col in symbols:\n",
    "            loop_list.append(loop_df[col].sum())\n",
    "\n",
    "        #print(len(out_df.columns),len(loop_list))\n",
    "        #print(out_df.columns)\n",
    "        out_df.loc[len(out_df.index)] = loop_list \n",
    "        \n",
    "        print(f\"{group[0]} {len(loop_df)} Comments in {round(time.time() - start_time,2)}s\")\n",
    "    print(\"Aggregation Complete!\")\n",
    "    return out_df\n",
    "\n",
    "#for col in df.columns[16:]:\n",
    "#    print(df[df[col] > 0 ].iloc[0]['created_utc'],col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin dataframe ticker symbol coding\n",
      "Encoding Time: 32.1s\n",
      "['date', 'total_posts', 'tfidf', 'score', 'awards', 'authors', 'threads', 'clov', 'sofi', 'wkhs', 'amd', 'gme', 'x', 'amc', 'clne', 'nio', 'mu', 'spce', 'bb']\n",
      "2012-08-24 29 Comments in 5.65s\n",
      "2012-08-25 19 Comments in 5.55s\n",
      "2012-08-26 13 Comments in 5.71s\n",
      "2012-08-27 11 Comments in 5.47s\n",
      "2012-08-28 5 Comments in 5.49s\n",
      "2012-08-29 5 Comments in 5.98s\n",
      "2013-05-12 6 Comments in 5.57s\n",
      "2013-05-13 22 Comments in 5.55s\n",
      "2013-05-14 30 Comments in 5.55s\n",
      "2013-05-15 20 Comments in 5.57s\n",
      "2013-05-16 8 Comments in 5.6s\n",
      "2013-05-17 3 Comments in 5.61s\n",
      "2014-04-10 19 Comments in 5.51s\n",
      "2014-04-11 65 Comments in 5.51s\n",
      "2014-07-30 20 Comments in 5.5s\n",
      "2014-07-31 25 Comments in 5.56s\n",
      "2014-08-01 16 Comments in 5.61s\n",
      "2014-08-02 4 Comments in 6.17s\n",
      "2014-08-03 1 Comments in 5.47s\n",
      "2014-08-04 13 Comments in 5.43s\n",
      "2014-08-05 2 Comments in 5.49s\n",
      "2014-08-06 4 Comments in 5.53s\n",
      "2015-04-18 4 Comments in 5.54s\n",
      "2015-04-19 89 Comments in 5.6s\n",
      "2016-02-05 84 Comments in 5.9s\n",
      "2016-12-30 86 Comments in 5.74s\n",
      "2017-09-11 50 Comments in 5.84s\n",
      "2017-09-12 32 Comments in 5.67s\n",
      "2017-10-18 89 Comments in 5.71s\n",
      "2017-11-23 76 Comments in 5.65s\n",
      "2017-11-24 16 Comments in 5.69s\n",
      "2017-12-30 94 Comments in 5.63s\n",
      "2018-02-04 52 Comments in 5.67s\n",
      "2018-02-05 32 Comments in 5.63s\n",
      "2018-03-13 91 Comments in 5.99s\n",
      "2018-04-18 44 Comments in 5.67s\n",
      "2018-04-19 41 Comments in 5.62s\n",
      "2018-05-25 91 Comments in 5.63s\n",
      "2018-06-30 11 Comments in 5.61s\n",
      "2018-07-01 74 Comments in 5.63s\n",
      "2018-08-06 177 Comments in 5.68s\n",
      "2018-08-11 159 Comments in 5.61s\n",
      "2018-08-20 180 Comments in 5.76s\n",
      "2018-08-29 93 Comments in 5.69s\n",
      "2018-09-07 261 Comments in 5.67s\n",
      "2018-09-12 86 Comments in 5.63s\n",
      "2018-09-16 179 Comments in 5.82s\n",
      "2018-09-21 90 Comments in 6.0s\n",
      "2018-09-25 249 Comments in 5.68s\n",
      "2018-09-30 88 Comments in 5.72s\n",
      "2018-10-04 158 Comments in 5.67s\n",
      "2018-10-09 83 Comments in 5.67s\n",
      "2018-10-13 183 Comments in 5.65s\n",
      "2018-10-14 135 Comments in 5.74s\n",
      "2018-10-23 83 Comments in 5.63s\n",
      "2018-11-01 178 Comments in 5.72s\n",
      "2018-11-10 88 Comments in 5.68s\n",
      "2018-11-19 272 Comments in 6.22s\n",
      "2018-11-24 89 Comments in 6.19s\n",
      "2018-11-28 170 Comments in 6.46s\n",
      "2018-12-03 88 Comments in 6.35s\n",
      "2018-12-07 266 Comments in 6.24s\n",
      "2018-12-12 90 Comments in 6.24s\n",
      "2018-12-16 174 Comments in 7.5s\n",
      "2018-12-25 178 Comments in 6.79s\n",
      "2018-12-26 85 Comments in 6.23s\n",
      "2019-01-04 95 Comments in 6.09s\n",
      "2019-01-13 193 Comments in 6.13s\n",
      "2019-01-22 97 Comments in 6.13s\n",
      "2019-01-31 288 Comments in 7.2s\n",
      "2019-02-09 94 Comments in 6.18s\n",
      "2019-02-18 188 Comments in 6.27s\n",
      "2019-02-23 96 Comments in 6.15s\n",
      "2019-02-27 186 Comments in 6.11s\n",
      "2019-03-04 94 Comments in 6.34s\n",
      "2019-03-08 323 Comments in 6.21s\n",
      "2019-03-09 45 Comments in 6.23s\n",
      "2019-03-18 93 Comments in 6.09s\n",
      "2019-03-27 191 Comments in 6.19s\n",
      "2019-04-05 95 Comments in 6.29s\n",
      "2019-04-14 286 Comments in 6.08s\n",
      "2019-04-23 96 Comments in 6.14s\n",
      "2019-05-02 189 Comments in 6.43s\n",
      "2019-05-11 91 Comments in 6.18s\n",
      "2019-05-20 151 Comments in 6.29s\n",
      "2019-05-21 130 Comments in 6.26s\n",
      "2019-05-25 95 Comments in 6.33s\n",
      "2019-05-30 189 Comments in 6.28s\n",
      "2019-06-08 192 Comments in 6.11s\n",
      "2019-06-17 98 Comments in 6.35s\n",
      "2019-06-21 79 Comments in 6.19s\n",
      "2019-06-22 13 Comments in 6.3s\n",
      "2019-06-26 361 Comments in 6.19s\n",
      "2019-07-05 95 Comments in 6.1s\n",
      "2019-07-10 89 Comments in 6.22s\n",
      "2019-07-14 274 Comments in 6.2s\n",
      "2019-07-19 94 Comments in 6.34s\n",
      "2019-07-23 189 Comments in 6.31s\n",
      "2019-07-28 92 Comments in 6.26s\n",
      "2019-08-02 468 Comments in 6.4s\n",
      "2019-09-07 98 Comments in 6.73s\n",
      "2019-10-14 95 Comments in 6.26s\n",
      "2019-11-19 94 Comments in 6.35s\n",
      "2019-12-26 93 Comments in 6.28s\n",
      "2020-01-31 91 Comments in 6.27s\n",
      "2020-03-08 85 Comments in 6.26s\n",
      "2020-04-13 91 Comments in 6.19s\n",
      "2020-05-20 98 Comments in 6.33s\n",
      "2020-06-25 362 Comments in 6.42s\n",
      "2020-06-26 692 Comments in 6.13s\n",
      "2020-06-27 1110 Comments in 6.23s\n",
      "2020-06-28 649 Comments in 6.29s\n",
      "2020-06-29 1083 Comments in 6.43s\n",
      "2020-06-30 817 Comments in 6.13s\n",
      "2020-07-01 920 Comments in 6.09s\n",
      "2020-07-02 923 Comments in 6.26s\n",
      "2020-07-03 930 Comments in 6.19s\n",
      "2020-07-04 1295 Comments in 6.47s\n",
      "2020-07-05 927 Comments in 6.17s\n",
      "2020-07-06 708 Comments in 6.35s\n",
      "2020-07-07 999 Comments in 6.22s\n",
      "2020-07-08 638 Comments in 6.25s\n",
      "2020-07-09 1182 Comments in 6.6s\n",
      "2020-07-10 809 Comments in 6.67s\n",
      "2020-07-11 1065 Comments in 6.2s\n",
      "2020-07-12 709 Comments in 6.22s\n",
      "2020-07-13 1085 Comments in 6.1s\n",
      "2020-07-14 1170 Comments in 6.38s\n",
      "2020-07-15 951 Comments in 6.16s\n",
      "2020-07-16 985 Comments in 6.15s\n",
      "2020-07-17 524 Comments in 6.39s\n",
      "2020-07-18 1220 Comments in 6.16s\n",
      "2020-07-19 792 Comments in 6.37s\n",
      "2020-07-20 1038 Comments in 6.17s\n",
      "2020-07-21 540 Comments in 6.2s\n",
      "2020-07-22 1155 Comments in 6.4s\n",
      "2020-07-23 1064 Comments in 6.55s\n",
      "2020-07-24 824 Comments in 6.21s\n",
      "2020-07-25 401 Comments in 6.23s\n",
      "2020-07-26 563 Comments in 6.52s\n",
      "2020-07-27 1158 Comments in 6.42s\n",
      "2020-07-28 801 Comments in 6.45s\n",
      "2020-07-29 735 Comments in 6.63s\n",
      "2020-07-30 991 Comments in 6.82s\n",
      "2020-07-31 1251 Comments in 6.29s\n",
      "2020-08-01 1302 Comments in 6.45s\n",
      "2020-08-02 626 Comments in 6.16s\n",
      "2020-08-03 1111 Comments in 6.16s\n",
      "2020-08-04 807 Comments in 6.27s\n",
      "2020-08-05 919 Comments in 6.2s\n",
      "2020-08-06 920 Comments in 6.23s\n",
      "2020-08-07 1033 Comments in 6.16s\n",
      "2020-08-08 927 Comments in 6.71s\n",
      "2020-08-09 1108 Comments in 6.24s\n",
      "2020-08-10 909 Comments in 6.2s\n",
      "2020-08-11 923 Comments in 6.38s\n",
      "2020-08-12 998 Comments in 6.26s\n",
      "2020-08-13 718 Comments in 6.46s\n",
      "2020-08-14 903 Comments in 6.39s\n",
      "2020-08-15 1072 Comments in 6.27s\n",
      "2020-08-16 823 Comments in 5.99s\n",
      "2020-08-17 1000 Comments in 5.89s\n",
      "2020-08-18 634 Comments in 5.88s\n",
      "2020-08-19 1628 Comments in 6.28s\n",
      "2020-08-20 644 Comments in 5.87s\n",
      "2020-08-21 1013 Comments in 5.85s\n",
      "2020-08-22 803 Comments in 6.01s\n",
      "2020-08-23 1062 Comments in 6.35s\n",
      "2020-08-24 890 Comments in 6.54s\n",
      "2020-08-25 975 Comments in 6.25s\n",
      "2020-08-26 724 Comments in 6.83s\n",
      "2020-08-27 802 Comments in 6.59s\n",
      "2020-08-28 922 Comments in 6.36s\n",
      "2020-08-29 1030 Comments in 6.4s\n",
      "2020-08-30 797 Comments in 6.41s\n",
      "2020-08-31 984 Comments in 6.37s\n",
      "2020-09-01 913 Comments in 6.16s\n",
      "2020-09-02 1073 Comments in 6.41s\n",
      "2020-09-03 630 Comments in 6.56s\n",
      "2020-09-04 1073 Comments in 6.29s\n",
      "2020-09-05 646 Comments in 6.32s\n",
      "2020-09-06 1375 Comments in 6.8s\n",
      "2020-09-07 1174 Comments in 5.85s\n",
      "2020-09-08 905 Comments in 5.92s\n",
      "2020-09-09 893 Comments in 5.88s\n",
      "2020-09-10 1094 Comments in 5.89s\n",
      "2020-09-11 817 Comments in 6.28s\n",
      "2020-09-12 710 Comments in 6.09s\n",
      "2020-09-13 869 Comments in 6.13s\n",
      "2020-09-14 968 Comments in 6.03s\n",
      "2020-09-15 975 Comments in 5.83s\n",
      "2020-09-16 1141 Comments in 5.85s\n",
      "2020-09-17 619 Comments in 5.79s\n",
      "2020-09-18 956 Comments in 5.94s\n",
      "2020-09-19 604 Comments in 6.34s\n",
      "2020-09-20 1111 Comments in 6.27s\n",
      "2020-09-21 597 Comments in 7.06s\n",
      "2020-09-22 362 Comments in 6.35s\n",
      "2020-09-23 801 Comments in 6.31s\n",
      "2020-09-24 1194 Comments in 6.06s\n",
      "2020-09-25 598 Comments in 5.68s\n",
      "2020-09-26 971 Comments in 5.69s\n",
      "2020-09-27 649 Comments in 5.72s\n",
      "2020-09-28 785 Comments in 5.81s\n",
      "2020-09-29 1002 Comments in 5.8s\n",
      "2020-09-30 1071 Comments in 6.25s\n",
      "2020-10-01 866 Comments in 5.76s\n",
      "2020-10-02 780 Comments in 5.73s\n",
      "2020-10-03 1133 Comments in 5.72s\n",
      "2020-10-04 1087 Comments in 5.68s\n",
      "2020-10-05 787 Comments in 5.94s\n",
      "2020-10-06 603 Comments in 5.7s\n",
      "2020-10-07 1007 Comments in 5.87s\n",
      "2020-10-08 985 Comments in 6.22s\n",
      "2020-10-09 1011 Comments in 6.42s\n",
      "2020-10-10 826 Comments in 6.43s\n",
      "2020-10-11 986 Comments in 6.42s\n",
      "2020-10-12 1243 Comments in 6.48s\n",
      "2020-10-13 743 Comments in 6.36s\n",
      "2020-10-14 1070 Comments in 6.92s\n",
      "2020-10-15 987 Comments in 6.4s\n",
      "2020-10-16 810 Comments in 6.7s\n",
      "2020-10-17 1063 Comments in 6.23s\n",
      "2020-10-18 1060 Comments in 6.28s\n",
      "2020-10-19 371 Comments in 6.27s\n",
      "2020-10-20 641 Comments in 6.35s\n",
      "2020-10-21 1260 Comments in 5.97s\n",
      "2020-10-22 640 Comments in 5.77s\n",
      "2020-10-23 1005 Comments in 5.91s\n",
      "2020-10-24 691 Comments in 5.94s\n",
      "2020-10-25 926 Comments in 6.18s\n",
      "2020-10-26 890 Comments in 6.06s\n",
      "2020-10-27 1094 Comments in 5.77s\n",
      "2020-10-28 726 Comments in 6.08s\n",
      "2020-10-29 893 Comments in 6.11s\n",
      "2020-10-30 717 Comments in 6.03s\n",
      "2020-10-31 1275 Comments in 6.11s\n",
      "2020-11-01 1150 Comments in 6.02s\n",
      "2020-11-02 891 Comments in 6.37s\n",
      "2020-11-03 914 Comments in 6.54s\n",
      "2020-11-04 1089 Comments in 6.97s\n",
      "2020-11-06 443 Comments in 6.53s\n",
      "2020-11-07 699 Comments in 6.29s\n",
      "2020-11-08 830 Comments in 6.31s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-09 1099 Comments in 6.23s\n",
      "2020-11-10 1183 Comments in 6.31s\n",
      "2020-11-11 821 Comments in 6.43s\n",
      "2020-11-12 725 Comments in 6.29s\n",
      "2020-11-13 1087 Comments in 5.92s\n",
      "2020-11-14 909 Comments in 6.34s\n",
      "2020-11-15 820 Comments in 6.53s\n",
      "2020-11-16 866 Comments in 6.29s\n",
      "2020-11-17 874 Comments in 6.34s\n",
      "2020-11-18 1332 Comments in 6.43s\n",
      "2020-11-19 1138 Comments in 6.35s\n",
      "2020-11-20 791 Comments in 6.42s\n",
      "2020-11-21 880 Comments in 6.42s\n",
      "2020-11-22 1084 Comments in 6.32s\n",
      "2020-11-23 834 Comments in 6.43s\n",
      "2020-11-24 743 Comments in 6.26s\n",
      "2020-11-25 748 Comments in 6.39s\n",
      "2020-11-26 912 Comments in 6.38s\n",
      "2020-11-27 987 Comments in 6.3s\n",
      "2020-11-28 695 Comments in 6.45s\n",
      "2020-11-29 994 Comments in 6.39s\n",
      "2020-11-30 808 Comments in 6.31s\n",
      "2020-12-01 1780 Comments in 6.59s\n",
      "2020-12-02 1603 Comments in 6.23s\n",
      "2020-12-03 1279 Comments in 6.41s\n",
      "2020-12-04 1475 Comments in 6.63s\n",
      "2020-12-05 1567 Comments in 6.26s\n",
      "2020-12-06 2259 Comments in 6.53s\n",
      "2020-12-07 1883 Comments in 6.34s\n",
      "2020-12-08 2228 Comments in 6.45s\n",
      "2020-12-09 1776 Comments in 6.37s\n",
      "2020-12-10 1703 Comments in 6.4s\n",
      "2020-12-11 2217 Comments in 6.33s\n",
      "2020-12-12 1623 Comments in 6.36s\n",
      "2020-12-13 1480 Comments in 6.45s\n",
      "2020-12-14 1607 Comments in 6.39s\n",
      "2020-12-15 2161 Comments in 6.45s\n",
      "2020-12-16 2065 Comments in 6.29s\n",
      "2020-12-17 2084 Comments in 6.35s\n",
      "2020-12-18 1281 Comments in 6.52s\n",
      "2020-12-19 2073 Comments in 6.24s\n",
      "2020-12-20 1747 Comments in 6.35s\n",
      "2020-12-21 2142 Comments in 7.47s\n",
      "2020-12-22 2209 Comments in 6.62s\n",
      "2020-12-23 1891 Comments in 6.53s\n",
      "2020-12-24 2472 Comments in 6.86s\n",
      "2020-12-25 1367 Comments in 6.24s\n",
      "2020-12-26 2062 Comments in 7.03s\n",
      "2020-12-27 1776 Comments in 6.49s\n",
      "2020-12-28 1319 Comments in 6.95s\n",
      "2020-12-29 1964 Comments in 6.59s\n",
      "2020-12-30 1869 Comments in 6.57s\n",
      "2020-12-31 1962 Comments in 6.15s\n",
      "2021-01-01 2154 Comments in 6.19s\n",
      "2021-01-02 2247 Comments in 6.33s\n",
      "2021-01-03 1571 Comments in 6.32s\n",
      "2021-01-04 1702 Comments in 5.82s\n",
      "2021-01-05 1723 Comments in 5.85s\n",
      "2021-01-06 2211 Comments in 5.79s\n",
      "2021-01-07 1748 Comments in 5.88s\n",
      "2021-01-08 1740 Comments in 5.81s\n",
      "2021-01-09 1696 Comments in 5.87s\n",
      "2021-01-10 1579 Comments in 5.85s\n",
      "2021-01-11 1758 Comments in 5.84s\n",
      "2021-01-12 1998 Comments in 6.11s\n",
      "2021-01-13 1513 Comments in 5.98s\n",
      "2021-01-14 2525 Comments in 5.76s\n",
      "2021-01-15 1419 Comments in 5.8s\n",
      "2021-01-16 2188 Comments in 6.07s\n",
      "2021-01-17 1945 Comments in 5.85s\n",
      "2021-01-18 1969 Comments in 6.28s\n",
      "2021-01-19 1550 Comments in 6.07s\n",
      "2021-01-20 1282 Comments in 5.95s\n",
      "2021-01-21 2471 Comments in 6.71s\n",
      "2021-01-22 2720 Comments in 6.21s\n",
      "2021-01-23 3321 Comments in 6.32s\n",
      "2021-01-24 68 Comments in 6.38s\n",
      "2021-01-27 730 Comments in 6.31s\n",
      "2021-01-28 1170 Comments in 6.24s\n",
      "2021-01-29 1426 Comments in 6.31s\n",
      "2021-01-30 2079 Comments in 6.49s\n",
      "2021-01-31 1031 Comments in 6.85s\n",
      "2021-02-01 1181 Comments in 6.15s\n",
      "2021-02-02 2105 Comments in 6.36s\n",
      "2021-02-03 487 Comments in 6.26s\n",
      "2021-02-07 362 Comments in 6.32s\n",
      "2021-02-08 1033 Comments in 6.23s\n",
      "2021-02-09 771 Comments in 6.35s\n",
      "2021-02-10 1064 Comments in 6.13s\n",
      "2021-02-11 896 Comments in 5.85s\n",
      "2021-02-12 1254 Comments in 5.95s\n",
      "2021-02-13 708 Comments in 6.49s\n",
      "2021-02-14 809 Comments in 5.9s\n",
      "2021-02-15 1376 Comments in 5.84s\n",
      "2021-02-16 550 Comments in 5.82s\n",
      "2021-02-17 1418 Comments in 5.87s\n",
      "2021-02-18 975 Comments in 5.99s\n",
      "2021-02-19 931 Comments in 6.43s\n",
      "2021-02-20 1453 Comments in 6.38s\n",
      "2021-02-21 1574 Comments in 5.81s\n",
      "2021-02-22 1676 Comments in 6.07s\n",
      "2021-02-23 1579 Comments in 5.86s\n",
      "2021-02-24 1583 Comments in 5.82s\n",
      "2021-02-25 1453 Comments in 5.84s\n",
      "2021-02-26 1437 Comments in 5.96s\n",
      "2021-03-02 754 Comments in 5.87s\n",
      "2021-03-03 1382 Comments in 5.89s\n",
      "2021-03-04 1699 Comments in 6.35s\n",
      "2021-03-07 709 Comments in 6.41s\n",
      "2021-03-08 882 Comments in 6.41s\n",
      "2021-03-09 1258 Comments in 6.15s\n",
      "2021-03-10 1918 Comments in 6.08s\n",
      "2021-03-11 1398 Comments in 7.1s\n",
      "2021-03-12 1467 Comments in 6.67s\n",
      "2021-03-13 1607 Comments in 6.47s\n",
      "2021-03-14 1617 Comments in 5.96s\n",
      "2021-03-15 3107 Comments in 6.35s\n",
      "2021-03-16 5196 Comments in 6.42s\n",
      "2021-03-17 1939 Comments in 5.9s\n",
      "2021-03-27 561 Comments in 5.95s\n",
      "2021-03-28 1446 Comments in 6.2s\n",
      "2021-03-29 1230 Comments in 5.87s\n",
      "2021-03-30 1475 Comments in 6.03s\n",
      "2021-03-31 1380 Comments in 6.22s\n",
      "2021-04-01 1654 Comments in 6.22s\n",
      "2021-04-02 1137 Comments in 6.18s\n",
      "2021-04-03 1468 Comments in 6.22s\n",
      "2021-04-04 1569 Comments in 6.07s\n",
      "2021-04-05 1789 Comments in 6.05s\n",
      "2021-04-06 1146 Comments in 5.95s\n",
      "2021-04-07 1935 Comments in 6.05s\n",
      "2021-04-08 1545 Comments in 6.24s\n",
      "2021-04-09 750 Comments in 6.24s\n",
      "2021-04-13 167 Comments in 6.09s\n",
      "2021-04-14 1369 Comments in 5.97s\n",
      "2021-04-15 1204 Comments in 6.09s\n",
      "2021-04-16 1837 Comments in 6.04s\n",
      "2021-04-17 1327 Comments in 6.15s\n",
      "2021-04-18 986 Comments in 6.48s\n",
      "2021-04-19 527 Comments in 5.93s\n",
      "2021-04-20 1077 Comments in 6.02s\n",
      "2021-04-21 656 Comments in 6.33s\n",
      "2021-04-22 1001 Comments in 6.09s\n",
      "2021-04-23 702 Comments in 6.08s\n",
      "2021-04-24 843 Comments in 6.07s\n",
      "2021-04-25 1278 Comments in 6.58s\n",
      "2021-04-26 867 Comments in 6.3s\n",
      "2021-04-27 895 Comments in 7.24s\n",
      "2021-04-28 524 Comments in 6.71s\n",
      "2021-04-29 797 Comments in 7.79s\n",
      "2021-04-30 992 Comments in 6.63s\n",
      "2021-05-01 977 Comments in 6.22s\n",
      "2021-05-02 894 Comments in 6.14s\n",
      "2021-05-03 887 Comments in 6.36s\n",
      "2021-05-04 968 Comments in 5.87s\n",
      "2021-05-05 944 Comments in 5.79s\n",
      "2021-05-06 750 Comments in 5.84s\n",
      "2021-05-07 996 Comments in 6.35s\n",
      "2021-05-08 899 Comments in 6.25s\n",
      "2021-05-09 931 Comments in 5.83s\n",
      "2021-05-10 1136 Comments in 6.06s\n",
      "2021-05-11 601 Comments in 6.21s\n",
      "2021-05-12 998 Comments in 6.23s\n",
      "2021-05-13 739 Comments in 5.95s\n",
      "2021-05-14 784 Comments in 6.19s\n",
      "2021-05-15 1186 Comments in 6.13s\n",
      "2021-05-16 954 Comments in 5.93s\n",
      "2021-05-17 1205 Comments in 5.85s\n",
      "2021-05-18 862 Comments in 5.83s\n",
      "2021-05-19 1290 Comments in 5.96s\n",
      "2021-05-20 835 Comments in 5.86s\n",
      "2021-05-21 700 Comments in 6.27s\n",
      "2021-05-22 1002 Comments in 5.92s\n",
      "2021-05-23 1142 Comments in 5.81s\n",
      "2021-05-24 767 Comments in 5.89s\n",
      "2021-05-25 812 Comments in 5.83s\n",
      "2021-05-26 1060 Comments in 5.87s\n",
      "2021-05-27 823 Comments in 5.8s\n",
      "2021-05-28 1426 Comments in 5.82s\n",
      "2021-05-29 509 Comments in 5.87s\n",
      "2021-05-30 859 Comments in 5.89s\n",
      "2021-05-31 1071 Comments in 5.86s\n",
      "2021-06-01 722 Comments in 5.85s\n",
      "2021-06-02 737 Comments in 6.2s\n",
      "2021-06-03 756 Comments in 6.66s\n",
      "2021-06-04 667 Comments in 6.79s\n",
      "2021-06-05 1025 Comments in 5.95s\n",
      "2021-06-06 582 Comments in 5.88s\n",
      "2021-06-07 1327 Comments in 6.23s\n",
      "2021-06-08 468 Comments in 7.09s\n",
      "2021-06-09 1063 Comments in 6.77s\n",
      "2021-06-10 700 Comments in 7.83s\n",
      "2021-06-11 772 Comments in 6.93s\n",
      "2021-06-12 907 Comments in 7.36s\n",
      "2021-06-13 863 Comments in 6.25s\n",
      "2021-06-14 784 Comments in 6.47s\n",
      "2021-06-15 640 Comments in 5.89s\n",
      "2021-06-16 1080 Comments in 6.05s\n",
      "2021-06-17 880 Comments in 5.75s\n",
      "2021-06-18 919 Comments in 5.72s\n",
      "2021-06-19 793 Comments in 5.69s\n",
      "2021-06-20 1085 Comments in 5.79s\n",
      "2021-06-21 567 Comments in 5.75s\n",
      "2021-06-22 557 Comments in 5.76s\n",
      "2021-06-23 694 Comments in 5.73s\n",
      "2021-06-24 513 Comments in 5.78s\n",
      "2021-06-25 1017 Comments in 5.74s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_posts</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>score</th>\n",
       "      <th>awards</th>\n",
       "      <th>authors</th>\n",
       "      <th>threads</th>\n",
       "      <th>clov</th>\n",
       "      <th>sofi</th>\n",
       "      <th>wkhs</th>\n",
       "      <th>amd</th>\n",
       "      <th>gme</th>\n",
       "      <th>x</th>\n",
       "      <th>amc</th>\n",
       "      <th>clne</th>\n",
       "      <th>nio</th>\n",
       "      <th>mu</th>\n",
       "      <th>spce</th>\n",
       "      <th>bb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>29</td>\n",
       "      <td>(0, 74752)\\t0.20781542118106996\\n  (0, 15154...</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>19</td>\n",
       "      <td>(0, 74752)\\t0.20781542118106996\\n  (0, 15154...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-08-26</td>\n",
       "      <td>13</td>\n",
       "      <td>(0, 74752)\\t0.20781542118106996\\n  (0, 15154...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-08-27</td>\n",
       "      <td>11</td>\n",
       "      <td>(0, 74752)\\t0.20781542118106996\\n  (0, 15154...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-08-28</td>\n",
       "      <td>5</td>\n",
       "      <td>(0, 74752)\\t0.20781542118106996\\n  (0, 15154...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2021-06-21</td>\n",
       "      <td>567</td>\n",
       "      <td>(0, 74752)\\t0.20781542118106996\\n  (0, 15154...</td>\n",
       "      <td>2878</td>\n",
       "      <td>8.0</td>\n",
       "      <td>429</td>\n",
       "      <td>89</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>557</td>\n",
       "      <td>(0, 74752)\\t0.20781542118106996\\n  (0, 15154...</td>\n",
       "      <td>3076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>400</td>\n",
       "      <td>113</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2021-06-23</td>\n",
       "      <td>694</td>\n",
       "      <td>(0, 74752)\\t0.20781542118106996\\n  (0, 15154...</td>\n",
       "      <td>4543</td>\n",
       "      <td>7.0</td>\n",
       "      <td>488</td>\n",
       "      <td>118</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>513</td>\n",
       "      <td>(0, 74752)\\t0.20781542118106996\\n  (0, 15154...</td>\n",
       "      <td>2857</td>\n",
       "      <td>5.0</td>\n",
       "      <td>397</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>1017</td>\n",
       "      <td>(0, 74752)\\t0.20781542118106996\\n  (0, 15154...</td>\n",
       "      <td>6312</td>\n",
       "      <td>10.0</td>\n",
       "      <td>543</td>\n",
       "      <td>116</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date total_posts  \\\n",
       "0    2012-08-24          29   \n",
       "1    2012-08-25          19   \n",
       "2    2012-08-26          13   \n",
       "3    2012-08-27          11   \n",
       "4    2012-08-28           5   \n",
       "..          ...         ...   \n",
       "446  2021-06-21         567   \n",
       "447  2021-06-22         557   \n",
       "448  2021-06-23         694   \n",
       "449  2021-06-24         513   \n",
       "450  2021-06-25        1017   \n",
       "\n",
       "                                                 tfidf score  awards authors  \\\n",
       "0      (0, 74752)\\t0.20781542118106996\\n  (0, 15154...    80     0.0      13   \n",
       "1      (0, 74752)\\t0.20781542118106996\\n  (0, 15154...    18     0.0       7   \n",
       "2      (0, 74752)\\t0.20781542118106996\\n  (0, 15154...    11     0.0       9   \n",
       "3      (0, 74752)\\t0.20781542118106996\\n  (0, 15154...    21     0.0       6   \n",
       "4      (0, 74752)\\t0.20781542118106996\\n  (0, 15154...     9     0.0       4   \n",
       "..                                                 ...   ...     ...     ...   \n",
       "446    (0, 74752)\\t0.20781542118106996\\n  (0, 15154...  2878     8.0     429   \n",
       "447    (0, 74752)\\t0.20781542118106996\\n  (0, 15154...  3076     2.0     400   \n",
       "448    (0, 74752)\\t0.20781542118106996\\n  (0, 15154...  4543     7.0     488   \n",
       "449    (0, 74752)\\t0.20781542118106996\\n  (0, 15154...  2857     5.0     397   \n",
       "450    (0, 74752)\\t0.20781542118106996\\n  (0, 15154...  6312    10.0     543   \n",
       "\n",
       "    threads clov sofi wkhs amd gme  x amc clne nio mu spce  bb  \n",
       "0         6    0    0    0   0   0  0   0    0   0  0    0   0  \n",
       "1         3    0    0    0   0   0  0   0    0   0  0    0   0  \n",
       "2         5    0    0    0   0   0  0   0    0   0  0    0   0  \n",
       "3         6    0    0    0   0   0  0   0    0   0  0    0   0  \n",
       "4         3    0    0    0   0   0  0   0    0   0  0    0   0  \n",
       "..      ...  ...  ...  ...  ..  .. ..  ..  ...  .. ..  ...  ..  \n",
       "446      89   10    0    7   4   9  1  10    7   5  3    0  12  \n",
       "447     113   14    2    2   5   8  1  10    7   1  0    0  10  \n",
       "448     118   21    0   11   3  12  0   9    3   6  0    3   8  \n",
       "449      72   18    0   12   4   1  0   6    3   0  1    1   5  \n",
       "450     116   11    2    2   3  14  2  13    7   0  0   28   9  \n",
       "\n",
       "[451 rows x 19 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Encode Comments\n",
    "df = encode_comments(raw_df)\n",
    "\n",
    "#//*** Aggregate and Process Comments\n",
    "ag_df = aggregate_comments(df)\n",
    "ag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \".\\\\data\\\\processed_reddit_basic_v2.csv.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Write File to disk\n",
    "ag_df.to_csv(output_filename,compression=\"zip\",index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
